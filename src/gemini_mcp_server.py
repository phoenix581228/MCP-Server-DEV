#!/usr/bin/env python3
"""
Gemini MCP Server v2

A Model Context Protocol (MCP) server that provides access to Google Gemini AI capabilities.
"""

import asyncio
import json
import logging
import os
import sys
from datetime import datetime
from typing import Any, Dict, List, Optional, Union

import google.generativeai as genai
from mcp.server.models import InitializationOptions
import mcp.types as types
from mcp.server import NotificationOptions, Server
import mcp.server.stdio

# é…ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("gemini-mcp-server")

# å»ºç«‹ä¼ºæœå™¨å¯¦ä¾‹
server = Server("gemini-mcp-server")

# å…¨åŸŸæ¨¡å‹è®Šæ•¸
model = None

def setup_authentication():
    """è¨­ç½® Google Gemini API èªè­‰"""
    global model
    
    api_key = os.getenv("GOOGLE_API_KEY")
    use_vertex_ai = os.getenv("GOOGLE_GENAI_USE_VERTEXAI", "false").lower() == "true"
    
    if use_vertex_ai:
        # ä½¿ç”¨ Vertex AI
        project_id = os.getenv("GOOGLE_CLOUD_PROJECT")
        location = os.getenv("GOOGLE_CLOUD_LOCATION", "us-central1")
        
        if not project_id:
            raise ValueError("GOOGLE_CLOUD_PROJECT is required for Vertex AI")
        
        logger.info(f"Using Vertex AI with project: {project_id}, location: {location}")
        
    elif api_key:
        # ä½¿ç”¨ Google AI Studio API
        genai.configure(api_key=api_key)
        logger.info("Using Google AI Studio API")
    else:
        raise ValueError("Either GOOGLE_API_KEY or Vertex AI credentials are required")
    
    # åˆå§‹åŒ–æ¨¡å‹
    model_name = os.getenv("GEMINI_MODEL", "gemini-1.5-flash")
    try:
        model = genai.GenerativeModel(model_name)
        logger.info(f"Initialized model: {model_name}")
    except Exception as e:
        logger.error(f"Failed to initialize model {model_name}: {e}")
        raise

@server.list_tools()
async def handle_list_tools() -> list[types.Tool]:
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„å·¥å…·"""
    return [
        types.Tool(
            name="gemini_chat",
            description="ä½¿ç”¨ Gemini é€²è¡ŒåŸºæœ¬å°è©±å’Œå•ç­”",
            inputSchema={
                "type": "object",
                "properties": {
                    "message": {
                        "type": "string",
                        "description": "è¦ç™¼é€çµ¦ Gemini çš„è¨Šæ¯"
                    },
                    "system_instruction": {
                        "type": "string",
                        "description": "å¯é¸çš„ç³»çµ±æŒ‡ä»¤ï¼Œç”¨æ–¼æŒ‡å° AI çš„è¡Œç‚º"
                    },
                    "temperature": {
                        "type": "number",
                        "description": "å‰µæ„åº¦æ§åˆ¶ (0.0-1.0)ï¼Œé è¨­ 0.7",
                        "minimum": 0.0,
                        "maximum": 1.0
                    }
                },
                "required": ["message"]
            }
        ),
        types.Tool(
            name="gemini_generate",
            description="ä½¿ç”¨ Gemini ç”Ÿæˆæ–‡æœ¬å…§å®¹",
            inputSchema={
                "type": "object",
                "properties": {
                    "prompt": {
                        "type": "string",
                        "description": "ç”Ÿæˆæ–‡æœ¬çš„æç¤ºè©"
                    },
                    "max_output_tokens": {
                        "type": "integer",
                        "description": "æœ€å¤§è¼¸å‡º token æ•¸é‡",
                        "minimum": 1,
                        "maximum": 8192
                    },
                    "temperature": {
                        "type": "number",
                        "description": "å‰µæ„åº¦æ§åˆ¶ (0.0-1.0)",
                        "minimum": 0.0,
                        "maximum": 1.0
                    }
                },
                "required": ["prompt"]
            }
        ),
        types.Tool(
            name="gemini_analyze_code",
            description="ä½¿ç”¨ Gemini åˆ†æç¨‹å¼ç¢¼ï¼Œæä¾›æ”¹é€²å»ºè­°",
            inputSchema={
                "type": "object",
                "properties": {
                    "code": {
                        "type": "string",
                        "description": "è¦åˆ†æçš„ç¨‹å¼ç¢¼"
                    },
                    "language": {
                        "type": "string",
                        "description": "ç¨‹å¼èªè¨€ (python, javascript, typescript, etc.)"
                    },
                    "analysis_type": {
                        "type": "string",
                        "description": "åˆ†æé¡å‹: review, optimize, debug, explain",
                        "enum": ["review", "optimize", "debug", "explain"]
                    }
                },
                "required": ["code"]
            }
        ),
        types.Tool(
            name="gemini_vision",
            description="ä½¿ç”¨ Gemini åˆ†æåœ–åƒå…§å®¹",
            inputSchema={
                "type": "object",
                "properties": {
                    "image_path": {
                        "type": "string",
                        "description": "åœ–åƒæª”æ¡ˆè·¯å¾‘"
                    },
                    "question": {
                        "type": "string",
                        "description": "é—œæ–¼åœ–åƒçš„å•é¡Œæˆ–åˆ†æè¦æ±‚"
                    }
                },
                "required": ["image_path"]
            }
        ),
        types.Tool(
            name="gemini_video_analysis",
            description="ä½¿ç”¨ Gemini åˆ†æå½±ç‰‡å…§å®¹ï¼Œæ”¯æ´è‡ªå‹•å„ªåŒ–",
            inputSchema={
                "type": "object",
                "properties": {
                    "video_path": {
                        "type": "string",
                        "description": "å½±ç‰‡æª”æ¡ˆè·¯å¾‘ (æ”¯æ´æ ¼å¼: mp4, mov, avi, mkv, webm)"
                    },
                    "question": {
                        "type": "string",
                        "description": "é—œæ–¼å½±ç‰‡çš„å•é¡Œæˆ–åˆ†æè¦æ±‚"
                    },
                    "analysis_type": {
                        "type": "string",
                        "description": "åˆ†æé¡å‹: summary (æ‘˜è¦), action (å‹•ä½œåˆ†æ), object (ç‰©é«”è­˜åˆ¥), text (æ–‡å­—è­˜åˆ¥)",
                        "enum": ["summary", "action", "object", "text"]
                    },
                    "auto_optimize": {
                        "type": "boolean",
                        "description": "æ˜¯å¦è‡ªå‹•å„ªåŒ–å½±ç‰‡æ ¼å¼ (é è¨­: true)",
                        "default": True
                    },
                    "target_resolution": {
                        "type": "string",
                        "description": "ç›®æ¨™è§£æåº¦: high (720p), standard (480p), low (360p)",
                        "enum": ["high", "standard", "low"]
                    }
                },
                "required": ["video_path"]
            }
        ),
        types.Tool(
            name="gemini_video_optimizer",
            description="åˆ†æä¸¦å„ªåŒ–å½±ç‰‡æª”æ¡ˆä»¥ç¬¦åˆ Gemini æ¨¡å‹éœ€æ±‚",
            inputSchema={
                "type": "object",
                "properties": {
                    "video_path": {
                        "type": "string", 
                        "description": "å½±ç‰‡æª”æ¡ˆè·¯å¾‘"
                    },
                    "target_model": {
                        "type": "string",
                        "description": "ç›®æ¨™ Gemini æ¨¡å‹",
                        "enum": ["gemini-2.0-flash-001", "gemini-2.5-flash", "gemini-2.5-pro", "gemini-1.5-pro", "gemini-1.5-flash"]
                    },
                    "analyze_only": {
                        "type": "boolean",
                        "description": "åƒ…åˆ†æä¸è™•ç† (é è¨­: false)",
                        "default": False
                    }
                },
                "required": ["video_path"]
            }
        ),
        types.Tool(
            name="gemini_batch_video_script_analysis",
            description="æ‰¹é‡å½±ç‰‡å ´è¨˜åˆ†æ - åˆ†æè³‡æ–™å¤¾ä¸­çš„æ‰€æœ‰å½±ç‰‡æª”æ¡ˆä¸¦ç”Ÿæˆè©³ç´°å ´è¨˜å ±å‘Š",
            inputSchema={
                "type": "object",
                "properties": {
                    "folder_path": {
                        "type": "string",
                        "description": "åŒ…å«å½±ç‰‡æª”æ¡ˆçš„è³‡æ–™å¤¾è·¯å¾‘"
                    },
                    "output_filename": {
                        "type": "string",
                        "description": "è¼¸å‡º JSON æª”æ¡ˆåç¨± (é è¨­: video_script_analysis.json)",
                        "default": "video_script_analysis.json"
                    },
                    "analysis_detail": {
                        "type": "string",
                        "description": "åˆ†æè©³ç´°åº¦: basic (åŸºæœ¬), detailed (è©³ç´°), comprehensive (å…¨é¢)",
                        "enum": ["basic", "detailed", "comprehensive"],
                        "default": "detailed"
                    },
                    "include_technical_analysis": {
                        "type": "boolean",
                        "description": "æ˜¯å¦åŒ…å«æŠ€è¡“åˆ†æ (é¡é ­ã€ç‡ˆå…‰ã€éŸ³éŸ¿ç­‰)",
                        "default": true
                    },
                    "max_concurrent_videos": {
                        "type": "integer",
                        "description": "åŒæ™‚è™•ç†çš„å½±ç‰‡æ•¸é‡ (é¿å… API é™åˆ¶)",
                        "minimum": 1,
                        "maximum": 5,
                        "default": 2
                    }
                },
                "required": ["folder_path"]
            }
        ),
        types.Tool(
            name="gemini_smart_preview",
            description="æ™ºèƒ½å…§å®¹é è¦½èˆ‡è­˜åˆ¥ - è·¯å¾‘Aï¼šAIè‡ªå‹•è­˜åˆ¥å½±ç‰‡å…§å®¹ä¸¦å»ºè­°æœ€ä½³åˆ†ææ¨¡å¼",
            inputSchema={
                "type": "object",
                "properties": {
                    "folder_path": {
                        "type": "string",
                        "description": "å½±ç‰‡è³‡æ–™å¤¾è·¯å¾‘"
                    },
                    "sample_count": {
                        "type": "integer",
                        "description": "é è¦½å½±ç‰‡æ•¸é‡ (é è¨­: 3)",
                        "minimum": 1,
                        "maximum": 10,
                        "default": 3
                    },
                    "content_types": {
                        "type": "array",
                        "items": {"type": "string"},
                        "description": "æœŸæœ›å…§å®¹é¡å‹ ['drone', 'interview', 'tutorial', 'demo', 'event']",
                        "default": ["drone"]
                    }
                },
                "required": ["folder_path"]
            }
        ),
        types.Tool(
            name="gemini_parallel_analysis",
            description="ä¸¦è¡Œè·¯å¾‘è™•ç†å™¨ - çµ±ä¸€è·¯å¾‘A/B/Cçš„æ™ºèƒ½åˆ†æèˆ‡ç”¨æˆ¶å¼•å°ä»‹é¢",
            inputSchema={
                "type": "object",
                "properties": {
                    "folder_path": {
                        "type": "string",
                        "description": "å½±ç‰‡è³‡æ–™å¤¾è·¯å¾‘"
                    },
                    "processing_mode": {
                        "type": "string",
                        "description": "è™•ç†æ¨¡å¼: auto (è·¯å¾‘Aè‡ªå‹•), guided (è·¯å¾‘Bå¼•å°), universal (è·¯å¾‘Cé€šç”¨)",
                        "enum": ["auto", "guided", "universal"],
                        "default": "auto"
                    },
                    "group_size": {
                        "type": "integer",
                        "description": "æ¯çµ„è™•ç†çš„å½±ç‰‡æ•¸é‡",
                        "minimum": 1,
                        "maximum": 5,
                        "default": 3
                    },
                    "cost_limit": {
                        "type": "number",
                        "description": "å–®æ¬¡è™•ç†çš„æˆæœ¬ä¸Šé™ (USD)",
                        "minimum": 0.1,
                        "maximum": 50.0,
                        "default": 5.0
                    },
                    "interactive_mode": {
                        "type": "boolean",
                        "description": "å•Ÿç”¨äº’å‹•æ¨¡å¼ (çµ„é–“ç¢ºèª)",
                        "default": true
                    }
                },
                "required": ["folder_path"]
            }
        )
    ]

@server.call_tool()
async def handle_call_tool(name: str, arguments: dict) -> list[types.TextContent]:
    """åŸ·è¡ŒæŒ‡å®šçš„å·¥å…·"""
    try:
        if name == "gemini_chat":
            return await chat_tool(arguments)
        elif name == "gemini_generate":
            return await generate_tool(arguments)
        elif name == "gemini_analyze_code":
            return await analyze_code_tool(arguments)
        elif name == "gemini_vision":
            return await vision_tool(arguments)
        elif name == "gemini_video_analysis":
            return await video_analysis_tool(arguments)
        elif name == "gemini_video_optimizer":
            return await video_optimizer_tool(arguments)
        elif name == "gemini_batch_video_script_analysis":
            return await batch_video_script_analysis_tool(arguments)
        elif name == "gemini_smart_preview":
            return await smart_preview_tool(arguments)
        elif name == "gemini_parallel_analysis":
            return await parallel_analysis_tool(arguments)
        else:
            raise ValueError(f"Unknown tool: {name}")
    
    except Exception as e:
        logger.error(f"Error calling tool {name}: {e}")
        return [
            types.TextContent(
                type="text",
                text=f"Error: {str(e)}"
            )
        ]

async def chat_tool(arguments: dict) -> list[types.TextContent]:
    """åŸºæœ¬å°è©±åŠŸèƒ½"""
    message = arguments["message"]
    system_instruction = arguments.get("system_instruction")
    temperature = arguments.get("temperature", 0.7)
    
    try:
        # è¨­ç½®ç”Ÿæˆé…ç½®
        generation_config = genai.types.GenerationConfig(
            temperature=temperature
        )
        
        # å¦‚æœæœ‰ç³»çµ±æŒ‡ä»¤ï¼Œå»ºç«‹æ–°çš„æ¨¡å‹å¯¦ä¾‹
        if system_instruction:
            chat_model = genai.GenerativeModel(
                model_name=model.model_name,
                generation_config=generation_config,
                system_instruction=system_instruction
            )
        else:
            chat_model = genai.GenerativeModel(
                model_name=model.model_name,
                generation_config=generation_config
            )
        
        response = await chat_model.generate_content_async(message)
        
        return [
            types.TextContent(
                type="text",
                text=response.text
            )
        ]
    
    except Exception as e:
        logger.error(f"Chat error: {e}")
        raise

async def generate_tool(arguments: dict) -> list[types.TextContent]:
    """æ–‡æœ¬ç”ŸæˆåŠŸèƒ½"""
    prompt = arguments["prompt"]
    max_tokens = arguments.get("max_output_tokens", 2048)
    temperature = arguments.get("temperature", 0.7)
    
    try:
        generation_config = genai.types.GenerationConfig(
            max_output_tokens=max_tokens,
            temperature=temperature
        )
        
        gen_model = genai.GenerativeModel(
            model_name=model.model_name,
            generation_config=generation_config
        )
        
        response = await gen_model.generate_content_async(prompt)
        
        return [
            types.TextContent(
                type="text",
                text=response.text
            )
        ]
    
    except Exception as e:
        logger.error(f"Generation error: {e}")
        raise

async def analyze_code_tool(arguments: dict) -> list[types.TextContent]:
    """ç¨‹å¼ç¢¼åˆ†æåŠŸèƒ½"""
    code = arguments["code"]
    language = arguments.get("language", "æœªæŒ‡å®š")
    analysis_type = arguments.get("analysis_type", "review")
    
    # å»ºç«‹åˆ†ææç¤ºè©
    analysis_prompts = {
        "review": f"è«‹å°ä»¥ä¸‹ {language} ç¨‹å¼ç¢¼é€²è¡Œä»£ç¢¼å¯©æŸ¥ï¼ŒæŒ‡å‡ºæ½›åœ¨å•é¡Œã€æ”¹é€²å»ºè­°å’Œæœ€ä½³å¯¦è¸ï¼š",
        "optimize": f"è«‹åˆ†æä»¥ä¸‹ {language} ç¨‹å¼ç¢¼çš„æ€§èƒ½ï¼Œæä¾›å„ªåŒ–å»ºè­°ï¼š",
        "debug": f"è«‹å¹«åŠ©èª¿è©¦ä»¥ä¸‹ {language} ç¨‹å¼ç¢¼ï¼Œæ‰¾å‡ºå¯èƒ½çš„éŒ¯èª¤å’Œå•é¡Œï¼š",
        "explain": f"è«‹è§£é‡‹ä»¥ä¸‹ {language} ç¨‹å¼ç¢¼çš„åŠŸèƒ½å’Œé‚è¼¯ï¼š"
    }
    
    prompt = f"{analysis_prompts.get(analysis_type, analysis_prompts['review'])}\n\n```{language}\n{code}\n```"
    
    try:
        response = await model.generate_content_async(prompt)
        
        return [
            types.TextContent(
                type="text",
                text=response.text
            )
        ]
    
    except Exception as e:
        logger.error(f"Code analysis error: {e}")
        raise

async def vision_tool(arguments: dict) -> list[types.TextContent]:
    """åœ–åƒåˆ†æåŠŸèƒ½"""
    image_path = arguments["image_path"]
    question = arguments.get("question", "è«‹æè¿°é€™å¼µåœ–ç‰‡çš„å…§å®¹")
    
    try:
        # æª¢æŸ¥åœ–ç‰‡æª”æ¡ˆæ˜¯å¦å­˜åœ¨
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"Image file not found: {image_path}")
        
        # è®€å–åœ–ç‰‡
        import PIL.Image
        image = PIL.Image.open(image_path)
        
        response = await model.generate_content_async([question, image])
        
        return [
            types.TextContent(
                type="text",
                text=response.text
            )
        ]
    
    except Exception as e:
        logger.error(f"Vision analysis error: {e}")
        raise

async def video_analysis_tool(arguments: dict) -> list[types.TextContent]:
    """å½±ç‰‡åˆ†æåŠŸèƒ½"""
    video_path = arguments["video_path"]
    question = arguments.get("question", "è«‹æè¿°é€™æ®µå½±ç‰‡çš„å…§å®¹")
    analysis_type = arguments.get("analysis_type", "summary")
    auto_optimize = arguments.get("auto_optimize", True)
    target_resolution = arguments.get("target_resolution")
    
    # åˆ†æé¡å‹å°æ‡‰çš„æç¤ºè©
    analysis_prompts = {
        "summary": """è«‹ä»¥å°ˆæ¥­å ´è¨˜å¸«çš„èº«ä»½ï¼Œç‚ºé€™æ®µå½±ç‰‡å‰µå»ºè©³ç´°çš„é¡é ­åˆ†è§£è¡¨ (Shot List)ã€‚

æŒ‰ç…§ä»¥ä¸‹æ ¼å¼åˆ†ææ¯å€‹é¡é ­ï¼š

## é¡é ­åˆ†è§£è¡¨ (Shot List)

**æ ¼å¼ç¯„ä¾‹ï¼š**
Shot 001 | TC: 00:00:00-00:00:03 | MS | ä¸»è§’æ­£é¢ä¸­æ™¯ï¼Œæ¡Œå‰é–±è®€æ–‡ä»¶ï¼Œè‡ªç„¶å…‰å¾å·¦å´çª—æˆ¶ç…§å…¥

**å¿…è¦è³‡è¨Šï¼š**
- **é¡é ­ç·¨è™Ÿ**: Shot 001, Shot 002... (ä¾åºç·¨è™Ÿ)
- **æ™‚é–“ç¢¼**: TC: HH:MM:SS-HH:MM:SS (ç²¾ç¢ºåˆ°ç§’)
- **æ™¯åˆ¥ä»£ç¢¼**: 
  - ECU (æ¥µç‰¹å¯«) - çœ¼ç›ã€å˜´éƒ¨ç­‰ç´°ç¯€
  - CU (ç‰¹å¯«) - é ­éƒ¨ç‚ºä¸»
  - MCU (ä¸­ç‰¹å¯«) - èƒ¸éƒ¨ä»¥ä¸Š
  - MS (ä¸­æ™¯) - è…°éƒ¨ä»¥ä¸Š
  - MLS (ä¸­é æ™¯) - è†è“‹ä»¥ä¸Š
  - LS (é æ™¯) - å…¨èº«
  - ELS (æ¥µé æ™¯) - ç’°å¢ƒç‚ºä¸»
- **é¡é ­æè¿°**: ä¸»é«”ã€å‹•ä½œã€è¦–è¦ºå…ƒç´ ã€å…‰ç·šæ¢ä»¶

**åˆ†æè¦æ±‚ï¼š**
1. æŒ‰æ™‚é–“é †åºåˆ†è§£æ‰€æœ‰å¯è­˜åˆ¥çš„é¡é ­
2. æº–ç¢ºæ¨™è¨˜æ¯å€‹é¡é ­çš„èµ·å§‹å’ŒçµæŸæ™‚é–“
3. ä½¿ç”¨æ¨™æº–æ™¯åˆ¥è¡“èª
4. ç°¡æ½”ä½†å®Œæ•´åœ°æè¿°æ¯å€‹é¡é ­çš„å…§å®¹""",
        "action": "è«‹åˆ†æå½±ç‰‡ä¸­çš„å‹•ä½œå’Œæ´»å‹•ï¼Œæè¿°äººç‰©æˆ–ç‰©é«”çš„è¡Œç‚ºï¼š",
        "object": "è«‹è­˜åˆ¥ä¸¦æè¿°å½±ç‰‡ä¸­å‡ºç¾çš„ç‰©é«”ã€äººç‰©å’Œå ´æ™¯å…ƒç´ ï¼š",
        "text": "è«‹è­˜åˆ¥å½±ç‰‡ä¸­å‡ºç¾çš„ä»»ä½•æ–‡å­—å…§å®¹ï¼š"
    }
    
    # æ ¹æ“šåˆ†æé¡å‹èª¿æ•´å•é¡Œ
    if analysis_type in analysis_prompts:
        enhanced_question = f"{analysis_prompts[analysis_type]} {question}"
    else:
        enhanced_question = question
    
    try:
        # æª¢æŸ¥å½±ç‰‡æª”æ¡ˆæ˜¯å¦å­˜åœ¨
        if not os.path.exists(video_path):
            raise FileNotFoundError(f"Video file not found: {video_path}")
        
        # æª¢æŸ¥æª”æ¡ˆæ ¼å¼
        supported_formats = ['.mp4', '.mov', '.avi', '.mkv', '.webm']
        file_ext = os.path.splitext(video_path)[1].lower()
        if file_ext not in supported_formats:
            raise ValueError(f"Unsupported video format: {file_ext}. Supported formats: {', '.join(supported_formats)}")
        
        # è‡ªå‹•å„ªåŒ–å½±ç‰‡ï¼ˆå¦‚æœå•Ÿç”¨ï¼‰
        final_video_path = video_path
        optimization_info = ""
        
        if auto_optimize:
            try:
                from video_optimizer import VideoOptimizer
                
                current_model = os.getenv("GEMINI_MODEL", "gemini-1.5-flash")
                optimizer = VideoOptimizer(current_model)
                
                # åˆ†æå½±ç‰‡
                video_info = optimizer.analyze_video(video_path)
                strategy = optimizer.get_optimization_strategy(video_info)
                
                # å¦‚æœæŒ‡å®šäº†ç›®æ¨™è§£æåº¦ï¼Œå»ºç«‹æ–°çš„ç­–ç•¥
                if target_resolution:
                    from video_optimizer import OptimizationStrategy
                    
                    # è§£æåº¦æ˜ å°„
                    resolution_map = {
                        "high": (1280, 720),      # 720p
                        "standard": (854, 480),   # 480p  
                        "low": (640, 360)         # 360p
                    }
                    
                    if target_resolution in resolution_map:
                        target_width, target_height = resolution_map[target_resolution]
                        
                        # å»ºç«‹æ–°çš„å„ªåŒ–ç­–ç•¥
                        strategy = OptimizationStrategy(
                            target_width=target_width,
                            target_height=target_height,
                            target_fps=strategy.target_fps,
                            target_bitrate=strategy.target_bitrate,
                            target_format=strategy.target_format,
                            quality_preset=strategy.quality_preset,
                            max_duration=strategy.max_duration
                        )
                        
                        logger.info(f"ğŸ¯ ç›®æ¨™è§£æåº¦è¨­å®šç‚º: {target_resolution} ({target_width}x{target_height})")
                
                # åˆ¤æ–·æ˜¯å¦éœ€è¦å„ªåŒ–è™•ç†
                needs_processing = (
                    target_resolution or  # ä½¿ç”¨è€…æŒ‡å®šè§£æåº¦
                    video_info.width > strategy.target_width or  # è§£æåº¦éé«˜
                    video_info.height > strategy.target_height or
                    video_info.file_size > 50 * 1024 * 1024  # æª”æ¡ˆå¤§æ–¼ 50MB
                )
                
                if needs_processing:
                    logger.info("å½±ç‰‡éœ€è¦å„ªåŒ–ï¼Œæ­£åœ¨è™•ç†...")
                    optimized_video_path = optimizer.optimize_video(video_path, strategy=strategy)
                    
                    if optimized_video_path and os.path.exists(optimized_video_path):
                        final_video_path = optimized_video_path
                        optimization_info = f"\nğŸ”§ å½±ç‰‡å·²å„ªåŒ–: {os.path.basename(optimized_video_path)}"
                        logger.info(f"å½±ç‰‡å„ªåŒ–å®Œæˆ: {final_video_path}")
                    else:
                        logger.warning("å½±ç‰‡å„ªåŒ–å¤±æ•—ï¼Œä½¿ç”¨åŸæª”æ¡ˆ")
                        optimization_info = f"\nâš ï¸ å„ªåŒ–å¤±æ•—ï¼Œä½¿ç”¨åŸæª”æ¡ˆ"
                else:
                    optimization_info = "\nâœ… å½±ç‰‡æ ¼å¼å·²æœ€ä½³åŒ–ï¼Œç„¡éœ€è™•ç†"
                    
            except ImportError:
                logger.warning("VideoOptimizer æœªå®‰è£ï¼Œè·³éè‡ªå‹•å„ªåŒ–")
                optimization_info = "\nâš ï¸ è‡ªå‹•å„ªåŒ–åŠŸèƒ½æœªå¯ç”¨"
            except Exception as e:
                logger.warning(f"è‡ªå‹•å„ªåŒ–å¤±æ•—: {e}")
                optimization_info = f"\nâš ï¸ è‡ªå‹•å„ªåŒ–å¤±æ•—: {str(e)}"
        
        # ä¸Šå‚³å½±ç‰‡æª”æ¡ˆåˆ° Gemini
        logger.info(f"Uploading video file: {final_video_path}")
        video_file = genai.upload_file(final_video_path)
        logger.info(f"Video uploaded successfully. URI: {video_file.uri}")
        
        # ç­‰å¾…æª”æ¡ˆè™•ç†å®Œæˆ
        import time
        while video_file.state.name == "PROCESSING":
            logger.info("Video processing...")
            time.sleep(2)
            video_file = genai.get_file(video_file.name)
        
        if video_file.state.name == "FAILED":
            raise ValueError(f"Video processing failed: {video_file.state}")
        
        logger.info("Video processing completed, generating analysis...")
        
        # é¸æ“‡æ”¯æ´å½±ç‰‡åˆ†æçš„æ¨¡å‹
        # å„ªå…ˆé †åºï¼šgemini-2.0-flash-001 > gemini-1.5-pro > gemini-1.5-flash
        video_models = ['gemini-2.0-flash-001', 'gemini-1.5-pro', 'gemini-1.5-flash']
        current_model = os.getenv("GEMINI_MODEL", "gemini-1.5-flash")
        
        # å¦‚æœç•¶å‰æ¨¡å‹æ”¯æ´å½±ç‰‡åˆ†æï¼Œä½¿ç”¨ç•¶å‰æ¨¡å‹ï¼Œå¦å‰‡ä½¿ç”¨ gemini-1.5-pro
        if current_model in video_models:
            video_model_name = current_model
        else:
            video_model_name = 'gemini-1.5-pro'
            logger.info(f"Current model {current_model} doesn't support video analysis, using {video_model_name}")
        
        # å»ºç«‹æ”¯æ´å½±ç‰‡åˆ†æçš„æ¨¡å‹
        vision_model = genai.GenerativeModel(video_model_name)
        logger.info(f"Using model {video_model_name} for video analysis")
        response = await vision_model.generate_content_async([enhanced_question, video_file])
        
        # æ¸…ç†ä¸Šå‚³çš„æª”æ¡ˆ
        try:
            genai.delete_file(video_file.name)
            logger.info("Uploaded video file cleaned up")
        except Exception as cleanup_error:
            logger.warning(f"Failed to cleanup uploaded file: {cleanup_error}")
        
        # æ¸…ç†å„ªåŒ–å¾Œçš„æª”æ¡ˆï¼ˆå¦‚æœä¸æ˜¯åŸå§‹æª”æ¡ˆï¼‰
        if final_video_path != video_path and os.path.exists(final_video_path):
            try:
                os.remove(final_video_path)
                logger.info("Optimized video file cleaned up")
            except Exception as cleanup_error:
                logger.warning(f"Failed to cleanup optimized file: {cleanup_error}")
        
        return [
            types.TextContent(
                type="text",
                text=response.text + optimization_info
            )
        ]
    
    except Exception as e:
        logger.error(f"Video analysis error: {e}")
        # å˜—è©¦æ¸…ç†å¯èƒ½çš„ä¸Šå‚³æª”æ¡ˆ
        try:
            if 'video_file' in locals():
                genai.delete_file(video_file.name)
        except:
            pass
        raise

async def video_optimizer_tool(arguments: dict) -> list[types.TextContent]:
    """å½±ç‰‡å„ªåŒ–å·¥å…·"""
    video_path = arguments["video_path"]
    target_model = arguments.get("target_model", os.getenv("GEMINI_MODEL", "gemini-1.5-flash"))
    analyze_only = arguments.get("analyze_only", False)
    
    try:
        from video_optimizer import VideoOptimizer
        
        optimizer = VideoOptimizer(target_model)
        
        if analyze_only:
            # åƒ…åˆ†ææ¨¡å¼
            summary = optimizer.get_processing_summary(video_path)
            return [
                types.TextContent(
                    type="text",
                    text=f"ğŸ“Š å½±ç‰‡åˆ†æå ±å‘Š\n\n{summary}"
                )
            ]
        else:
            # å®Œæ•´å„ªåŒ–æ¨¡å¼
            result = optimizer.optimize_video(video_path)
            
            if result['success']:
                response_text = f"âœ… å½±ç‰‡å„ªåŒ–å®Œæˆ\n\n"
                response_text += f"ğŸ“Š åŸå§‹æª”æ¡ˆ: {result['original_file']}\n"
                response_text += f"ğŸ¯ ç›®æ¨™æ¨¡å‹: {target_model}\n"
                response_text += f"ğŸ“ˆ è™•ç†çµæœ: {result['message']}\n\n"
                
                if len(result['optimized_files']) > 1:
                    response_text += f"ğŸ“ ç”Ÿæˆæª”æ¡ˆ ({len(result['optimized_files'])} å€‹):\n"
                    for i, file in enumerate(result['optimized_files'], 1):
                        response_text += f"  {i}. {file}\n"
                else:
                    response_text += f"ğŸ“ å„ªåŒ–æª”æ¡ˆ: {result['optimized_files'][0]}\n"
                
                # æ·»åŠ ç­–ç•¥è³‡è¨Š
                strategy = result['strategy']
                response_text += f"\nğŸ¯ å„ªåŒ–ç­–ç•¥:\n"
                response_text += f"  - è§£æåº¦: {strategy['target_resolution']}\n"
                response_text += f"  - å¹€ç‡: {strategy['target_fps']} fps\n"
                response_text += f"  - é ä¼° Token: {strategy['estimated_tokens']:,}\n"
                response_text += f"  - ä¸Šå‚³æ–¹å¼: {strategy['upload_method']}\n"
                
                if strategy['recommendations']:
                    response_text += f"\nğŸ’¡ å»ºè­°:\n"
                    for rec in strategy['recommendations']:
                        response_text += f"  - {rec}\n"
                
                return [
                    types.TextContent(
                        type="text",
                        text=response_text
                    )
                ]
            else:
                return [
                    types.TextContent(
                        type="text",
                        text=f"âŒ å„ªåŒ–å¤±æ•—: {result['message']}"
                    )
                ]
                
    except ImportError:
        return [
            types.TextContent(
                type="text",
                text="âŒ å½±ç‰‡å„ªåŒ–åŠŸèƒ½æœªå®‰è£\nè«‹ç¢ºä¿å·²å®‰è£ ffmpeg å’Œç›¸é—œä¾è³´"
            )
        ]
    except Exception as e:
        logger.error(f"Video optimization error: {e}")
        return [
            types.TextContent(
                type="text",
                text=f"âŒ å„ªåŒ–éç¨‹ç™¼ç”ŸéŒ¯èª¤: {str(e)}"
            )
        ]

async def batch_video_script_analysis_tool(arguments: dict) -> list[types.TextContent]:
    """æ‰¹é‡å½±ç‰‡å ´è¨˜åˆ†æå·¥å…·"""
    import glob
    import datetime
    from pathlib import Path
    
    try:
        folder_path = arguments["folder_path"]
        output_filename = arguments.get("output_filename", "video_script_analysis.json")
        analysis_detail = arguments.get("analysis_detail", "detailed")
        include_technical = arguments.get("include_technical_analysis", True)
        max_concurrent = arguments.get("max_concurrent_videos", 2)
        
        # æª¢æŸ¥è³‡æ–™å¤¾æ˜¯å¦å­˜åœ¨
        if not os.path.exists(folder_path):
            return [
                types.TextContent(
                    type="text",
                    text=f"âŒ è³‡æ–™å¤¾ä¸å­˜åœ¨: {folder_path}"
                )
            ]
        
        # æ”¯æ´çš„å½±ç‰‡æ ¼å¼
        video_extensions = ["*.mp4", "*.mov", "*.avi", "*.mkv", "*.webm", "*.m4v"]
        video_files = []
        
        for ext in video_extensions:
            video_files.extend(glob.glob(os.path.join(folder_path, ext)))
            video_files.extend(glob.glob(os.path.join(folder_path, ext.upper())))
        
        if not video_files:
            return [
                types.TextContent(
                    type="text",
                    text=f"âŒ åœ¨è³‡æ–™å¤¾ä¸­æœªæ‰¾åˆ°æ”¯æ´çš„å½±ç‰‡æª”æ¡ˆ: {folder_path}"
                )
            ]
        
        # æº–å‚™åˆ†æå ±å‘Šçµæ§‹
        project_name = os.path.basename(os.path.abspath(folder_path))
        analysis_report = {
            "project_name": project_name,
            "analysis_timestamp": datetime.datetime.now().isoformat(),
            "total_videos": len(video_files),
            "analysis_settings": {
                "detail_level": analysis_detail,
                "technical_analysis": include_technical,
                "max_concurrent": max_concurrent
            },
            "videos": [],
            "project_summary": {
                "total_duration": "00:00:00",
                "main_themes": [],
                "key_characters": [],
                "production_notes": ""
            }
        }
        
        # å®šç¾©å ´è¨˜åˆ†ææç¤ºè©
        def get_script_analysis_prompt(analysis_level, include_tech):
            base_prompt = """ä½ æ˜¯å°ˆæ¥­çš„å½±ç‰‡å ´è¨˜åˆ†æå¸«ï¼Œå°ˆç²¾æ–¼ç„¡äººæ©Ÿèˆªæ‹å½±ç‰‡åˆ†æã€‚è«‹å°é€™å€‹ç„¡äººæ©Ÿæ‹æ”çš„å½±ç‰‡é€²è¡Œè©³ç´°çš„å ´è¨˜åˆ†æï¼Œä¸¦ä»¥çµæ§‹åŒ–çš„æ–¹å¼å›æ‡‰ã€‚

## ğŸš ç„¡äººæ©Ÿå½±ç‰‡å ´è¨˜åˆ†æè¦æ±‚

### 1. åŸºæœ¬è³‡è¨Š
- å½±ç‰‡æ•´é«”æ™‚é•·å’Œä¸»è¦å…§å®¹æ‘˜è¦
- æ‹æ”é¡å‹è­˜åˆ¥ï¼ˆé¢¨æ™¯èˆªæ‹ã€å»ºç¯‰è¨˜éŒ„ã€æ´»å‹•è¿½è¹¤ã€æ¸¬é‡å‹˜æŸ¥ç­‰ï¼‰
- ç„¡äººæ©Ÿå‹è™Ÿæ¨æ¸¬ï¼ˆåŸºæ–¼ç•«è³ªã€ç©©å®šæ€§ã€é£›è¡Œç‰¹æ€§ï¼‰

### 2. èˆªæ‹å ´æ™¯åˆ†æï¼ˆæŒ‰æ™‚é–“è»¸åˆ†æ®µï¼‰
- å°‡å½±ç‰‡åˆ†å‰²ç‚ºä¸»è¦é£›è¡Œå ´æ™¯
- æ¯å€‹å ´æ™¯åŒ…å«ï¼š
  * æ™‚é–“è»¸ç¯„åœï¼ˆMM:SS-MM:SS æ ¼å¼ï¼‰
  * é£›è¡Œé«˜åº¦ä¼°æ¸¬ï¼ˆä½ç©º<30mã€ä¸­ç©º30-120mã€é«˜ç©º>120mï¼‰
  * æ‹æ”åœ°é»å’Œåœ°ç†ç’°å¢ƒæè¿°
  * ä¸»è¦æ‹æ”å°è±¡ï¼ˆå»ºç¯‰ã€æ™¯è§€ã€äººç¾¤ã€è»Šè¼›ç­‰ï¼‰
  * é£›è¡Œå‹•ä½œå’Œè»Œè·¡ï¼ˆæ‡¸åœã€ç’°ç¹ã€æ¨é€²ã€æ‹‰å‡ç­‰ï¼‰
  * é‡è¦åœ°æ¨™å’Œè¦–è¦ºå…ƒç´ 
  * å…‰ç·šæ¢ä»¶å’Œå¤©æ°£ç‹€æ³

### 3. ğŸ¥ ç„¡äººæ©Ÿæ”å½±æŠ€æ³•åˆ†æ
- é£›è¡Œæ¨¡å¼è­˜åˆ¥ï¼š
  * å®šé»æ‡¸åœæ‹æ”
  * ç’°ç¹é£›è¡Œï¼ˆOrbitï¼‰
  * ç›´ç·šæ¨é€²/æ‹‰é 
  * å´å‘é£›è¡Œï¼ˆParallaxï¼‰
  * å‚ç›´å‡é™
  * è·Ÿéš¨æ¨¡å¼
- é›²å°æ§åˆ¶æŠ€å·§ï¼š
  * ä¿¯è¦–è§’åº¦è®ŠåŒ–
  * æ°´å¹³è½‰å‘
  * å‚¾æ–œæ‹æ”
- æ§‹åœ–æ‡‰ç”¨ï¼š
  * é³¥ç°å…¨æ™¯
  * å¼•å°ç·šæ§‹åœ–
  * å‰æ™¯/èƒŒæ™¯å±¤æ¬¡"""

            if analysis_level == "comprehensive":
                base_prompt += """

### 3. è©³ç´°å…§å®¹åˆ†æ
- é€åˆ†é˜é—œéµäº‹ä»¶è¨˜éŒ„
- äººç‰©è¡¨æƒ…å’Œè‚¢é«”èªè¨€åˆ†æ
- å°è©±é‡é»å’Œé—œéµè©å½™
- è¦–è¦ºç¬¦è™Ÿå’Œéš±å«æ„ç¾©"""

            if include_tech:
                base_prompt += """

### 4. ğŸ”§ æŠ€è¡“å±¤é¢å°ˆæ¥­åˆ†æ
- ç„¡äººæ©Ÿé£›è¡ŒæŠ€è¡“ï¼š
  * é£›è¡Œè»Œè·¡å¹³æ»‘åº¦è©•ä¼°
  * é¢¨åŠ›å½±éŸ¿å’Œè£œå„Ÿèƒ½åŠ›
  * GPS å®šä½ç²¾åº¦è¡¨ç¾
  * é¿éšœç³»çµ±ä½¿ç”¨æƒ…æ³
- å½±åƒå“è³ªåˆ†æï¼š
  * é›²å°ç©©å®šæ€§æ•ˆæœ
  * é¡é ­ç•¸è®Šä¿®æ­£
  * æ›å…‰æ§åˆ¶å’Œå‹•æ…‹ç¯„åœ
  * è‰²å½©å¹³è¡¡å’Œé£½å’Œåº¦
- æ‹æ”åƒæ•¸æ¨æ¸¬ï¼š
  * å¿«é–€é€Ÿåº¦å’Œå‹•æ…‹æ¨¡ç³Š
  * ISO è¨­å®šå’Œå™ªé»æ§åˆ¶
  * è§£æåº¦å’Œç•«é¢å“è³ª
  * å¹€ç‡å’Œæµæš¢åº¦
- æ³•è¦éµå¾ªè©•ä¼°ï¼š
  * é£›è¡Œé«˜åº¦æ˜¯å¦åˆè¦
  * ç¦èˆªå€åŸŸé¿è®“
  * å®‰å…¨è·é›¢ç¶­æŒ
  * è¦–ç·šç¯„åœå…§æ“ä½œ"""

            base_prompt += """

### 5. ğŸ¬ ç„¡äººæ©Ÿèˆªæ‹è£½ä½œå»ºè­°
- é£›è¡ŒæŠ€å·§æ”¹é€²ï¼š
  * è»Œè·¡è¦åŠƒå„ªåŒ–å»ºè­°
  * é€Ÿåº¦æ§åˆ¶å»ºè­°
  * é«˜åº¦è®ŠåŒ–æŠ€å·§
  * è½‰å‘å¹³æ»‘åº¦æ”¹å–„
- æ‹æ”å“è³ªæå‡ï¼š
  * æ§‹åœ–æ”¹å–„æ–¹å‘
  * å…‰ç·šé‹ç”¨æŠ€å·§
  * è‰²å½©æ ¡æ­£å»ºè­°
  * ç©©å®šæ€§æ”¹å–„
- å¾Œè£½è™•ç†å»ºè­°ï¼š
  * è‰²å½©èª¿è‰²æ–¹å‘
  * ç©©å®šæ€§å¾Œè£½éœ€æ±‚
  * é€Ÿåº¦èª¿ç¯€å»ºè­°
  * éŸ³è»Œé…ç½®å»ºè­°
- å®‰å…¨èˆ‡æ³•è¦ï¼š
  * é£›è¡Œå®‰å…¨æ”¹å–„
  * æ³•è¦éµå¾ªæé†’
  * é¢¨éšªè©•ä¼°å»ºè­°

## ğŸ“ å›æ‡‰æ ¼å¼è¦æ±‚
è«‹ä»¥ JSON æ ¼å¼å›æ‡‰ï¼ŒåŒ…å«ä»¥ä¸‹çµæ§‹ï¼š
{
  "summary": "å½±ç‰‡æ•´é«”æ‘˜è¦",
  "drone_analysis": {
    "flight_patterns": ["é£›è¡Œæ¨¡å¼åˆ—è¡¨"],
    "altitude_ranges": "é«˜åº¦ç¯„åœ",
    "shooting_techniques": ["æ‹æ”æŠ€æ³•åˆ—è¡¨"]
  },
  "scenes": [
    {
      "timestamp": "MM:SS-MM:SS",
      "description": "å ´æ™¯æè¿°",
      "flight_action": "é£›è¡Œå‹•ä½œ",
      "subjects": ["æ‹æ”å°è±¡"],
      "technical_notes": "æŠ€è¡“å‚™è¨»"
    }
  ],
  "technical_analysis": {
    "image_quality": "å½±åƒå“è³ªè©•ä¼°",
    "flight_performance": "é£›è¡Œè¡¨ç¾",
    "equipment_assessment": "è¨­å‚™è©•ä¼°"
  },
  "production_suggestions": {
    "improvements": ["æ”¹å–„å»ºè­°"],
    "retakes": ["è£œæ‹å»ºè­°"],
    "post_production": ["å¾Œè£½å»ºè­°"]
  }
}

è«‹ä»¥å°ˆæ¥­ã€è©³ç´°ä¸”çµæ§‹åŒ–çš„æ–¹å¼åˆ†æï¼Œç¢ºä¿æä¾›å…·é«”çš„æ™‚é–“è»¸æ¨™è¨˜å’Œç„¡äººæ©Ÿå°ˆæ¥­è¡“èªã€‚"""
            
            return base_prompt
        
        # è™•ç†é€²åº¦è¿½è¹¤
        processed_count = 0
        failed_videos = []
        
        # åˆ†æ‰¹è™•ç†å½±ç‰‡
        for i in range(0, len(video_files), max_concurrent):
            batch = video_files[i:i+max_concurrent]
            batch_tasks = []
            
            for video_path in batch:
                batch_tasks.append(analyze_single_video(video_path, get_script_analysis_prompt(analysis_detail, include_technical)))
            
            # ä¸¦è¡Œè™•ç†ç•¶å‰æ‰¹æ¬¡
            batch_results = await asyncio.gather(*batch_tasks, return_exceptions=True)
            
            for video_path, result in zip(batch, batch_results):
                processed_count += 1
                
                if isinstance(result, Exception):
                    failed_videos.append({
                        "filename": os.path.basename(video_path),
                        "error": str(result)
                    })
                    logger.error(f"Failed to analyze {video_path}: {result}")
                    continue
                
                # ç²å–æª”æ¡ˆè³‡è¨Š
                file_size = os.path.getsize(video_path)
                file_size_mb = round(file_size / (1024 * 1024), 2)
                
                video_analysis = {
                    "filename": os.path.basename(video_path),
                    "file_path": video_path,
                    "file_size": f"{file_size_mb} MB",
                    "analysis_status": "completed",
                    "analysis": result
                }
                
                analysis_report["videos"].append(video_analysis)
                
                # é€²åº¦å›å ±
                progress = int((processed_count / len(video_files)) * 100)
                logger.info(f"è™•ç†é€²åº¦: {processed_count}/{len(video_files)} ({progress}%)")
        
        # ç”Ÿæˆå°ˆæ¡ˆç¸½çµ
        if analysis_report["videos"]:
            themes = []
            characters = []
            total_duration_seconds = 0
            
            for video in analysis_report["videos"]:
                analysis = video.get("analysis", {})
                if isinstance(analysis, dict):
                    themes.extend(analysis.get("themes", []))
                    characters.extend(analysis.get("characters", []))
            
            analysis_report["project_summary"]["main_themes"] = list(set(themes))[:10]
            analysis_report["project_summary"]["key_characters"] = list(set(characters))[:20]
            analysis_report["project_summary"]["production_notes"] = f"å…±åˆ†æ {len(analysis_report['videos'])} å€‹å½±ç‰‡æª”æ¡ˆ"
        
        # æ·»åŠ å¤±æ•—è¨˜éŒ„
        if failed_videos:
            analysis_report["failed_analyses"] = failed_videos
        
        # å„²å­˜ JSON å ±å‘Š
        output_path = os.path.join(folder_path, output_filename)
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(analysis_report, f, ensure_ascii=False, indent=2)
            
            # æˆåŠŸå ±å‘Š
            success_count = len(analysis_report["videos"])
            failed_count = len(failed_videos)
            
            response_text = f"""âœ… æ‰¹é‡å½±ç‰‡å ´è¨˜åˆ†æå®Œæˆï¼

ğŸ“Š è™•ç†çµæœ:
  - å°ˆæ¡ˆåç¨±: {project_name}
  - ç¸½å½±ç‰‡æ•¸: {len(video_files)}
  - æˆåŠŸåˆ†æ: {success_count}
  - å¤±æ•—æ•¸é‡: {failed_count}
  - åˆ†æç­‰ç´š: {analysis_detail}
  - æŠ€è¡“åˆ†æ: {'æ˜¯' if include_technical else 'å¦'}

ğŸ“ è¼¸å‡ºæª”æ¡ˆ: {output_path}

ğŸ¬ å ´è¨˜å ±å‘Šå…§å®¹:
  - æ¯å€‹å½±ç‰‡çš„è©³ç´°å ´æ™¯åˆ†æ
  - æ™‚é–“è»¸æ¨™è¨˜å’Œå…§å®¹æè¿°
  - äººç‰©ã€å‹•ä½œã€å°è©±è¨˜éŒ„"""

            if include_technical:
                response_text += """
  - æŠ€è¡“åˆ†æï¼ˆé¡é ­ã€ç‡ˆå…‰ã€éŸ³éŸ¿ï¼‰"""

            if failed_videos:
                response_text += f"""

âš ï¸ è™•ç†å¤±æ•—çš„æª”æ¡ˆ:"""
                for failed in failed_videos[:3]:  # åªé¡¯ç¤ºå‰3å€‹
                    response_text += f"""
  - {failed['filename']}: {failed['error'][:50]}..."""
                
                if len(failed_videos) > 3:
                    response_text += f"""
  - é‚„æœ‰ {len(failed_videos) - 3} å€‹æª”æ¡ˆå¤±æ•—"""

            return [
                types.TextContent(
                    type="text",
                    text=response_text
                )
            ]
            
        except Exception as e:
            return [
                types.TextContent(
                    type="text",
                    text=f"âŒ å„²å­˜å ±å‘Šå¤±æ•—: {str(e)}"
                )
            ]
            
    except Exception as e:
        logger.error(f"Batch video analysis error: {e}")
        return [
            types.TextContent(
                type="text",
                text=f"âŒ æ‰¹é‡åˆ†æéç¨‹ç™¼ç”ŸéŒ¯èª¤: {str(e)}"
            )
        ]

async def smart_preview_tool(arguments: dict) -> list[types.TextContent]:
    """æ™ºèƒ½å…§å®¹é è¦½èˆ‡è­˜åˆ¥ - è·¯å¾‘Aï¼šAIè‡ªå‹•è­˜åˆ¥"""
    folder_path = arguments["folder_path"]
    sample_count = arguments.get("sample_count", 3)
    content_types = arguments.get("content_types", ["drone"])
    
    try:
        # æƒæå½±ç‰‡æª”æ¡ˆ
        import glob
        video_files = []
        for ext in ["*.MOV", "*.mp4", "*.mov", "*.avi", "*.mkv", "*.webm"]:
            video_files.extend(glob.glob(os.path.join(folder_path, ext)))
        
        if not video_files:
            return [
                types.TextContent(
                    type="text",
                    text=f"âŒ æœªåœ¨ {folder_path} æ‰¾åˆ°å½±ç‰‡æª”æ¡ˆ"
                )
            ]
        
        # é¸æ“‡æ¨£æœ¬å½±ç‰‡ (å–å‰é¢å¹¾å€‹)
        sample_videos = video_files[:sample_count]
        
        preview_results = {
            "folder_path": folder_path,
            "total_videos": len(video_files),
            "sampled_videos": len(sample_videos),
            "content_analysis": [],
            "recommended_mode": "universal",
            "confidence_score": 0.0
        }
        
        # åˆ†ææ¯å€‹æ¨£æœ¬å½±ç‰‡
        content_analysis_prompt = """åˆ†æé€™å€‹å½±ç‰‡çš„å…§å®¹é¡å‹å’Œç‰¹å¾µï¼Œè«‹ä»¥JSONæ ¼å¼å›æ‡‰ï¼š
{
  "content_type": "drone|interview|tutorial|demo|event|other",
  "confidence": 0.8,
  "features": ["aerial_view", "technical_demo", "person_speaking"],
  "complexity": "low|medium|high",
  "recommended_analysis": "comprehensive|detailed|basic"
}"""
        
        for video_path in sample_videos:
            try:
                logger.info(f"é è¦½åˆ†æ: {os.path.basename(video_path)}")
                result = await analyze_single_video(video_path, content_analysis_prompt)
                
                # å¦‚æœæ˜¯å­—å…¸æ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨
                if isinstance(result, dict) and "content_type" in result:
                    content_info = result
                else:
                    # å˜—è©¦å¾å­—ç¬¦ä¸²è§£æJSON
                    import re
                    json_match = re.search(r'\{[^}]+\}', str(result))
                    if json_match:
                        try:
                            content_info = json.loads(json_match.group())
                        except:
                            content_info = {"content_type": "unknown", "confidence": 0.3}
                    else:
                        content_info = {"content_type": "unknown", "confidence": 0.3}
                
                content_info["filename"] = os.path.basename(video_path)
                preview_results["content_analysis"].append(content_info)
                
            except Exception as e:
                logger.error(f"é è¦½åˆ†æå¤±æ•— {video_path}: {e}")
                preview_results["content_analysis"].append({
                    "filename": os.path.basename(video_path),
                    "content_type": "error",
                    "confidence": 0.0,
                    "error": str(e)
                })
        
        # æ±ºå®šæ¨è–¦æ¨¡å¼
        if preview_results["content_analysis"]:
            # è¨ˆç®—å…§å®¹é¡å‹çš„ä¸€è‡´æ€§
            types_found = [item.get("content_type", "unknown") for item in preview_results["content_analysis"]]
            confidence_scores = [item.get("confidence", 0.0) for item in preview_results["content_analysis"]]
            
            most_common_type = max(set(types_found), key=types_found.count)
            type_consistency = types_found.count(most_common_type) / len(types_found)
            avg_confidence = sum(confidence_scores) / len(confidence_scores) if confidence_scores else 0.0
            
            overall_confidence = type_consistency * avg_confidence
            preview_results["confidence_score"] = overall_confidence
            preview_results["detected_content_type"] = most_common_type
            
            # æ¨è–¦è™•ç†æ¨¡å¼
            if overall_confidence > 0.7 and most_common_type in content_types:
                preview_results["recommended_mode"] = "auto"
            elif overall_confidence > 0.4:
                preview_results["recommended_mode"] = "guided"
            else:
                preview_results["recommended_mode"] = "universal"
        
        # ç”Ÿæˆå ±å‘Š
        response_text = f"""ğŸ” æ™ºèƒ½å…§å®¹é è¦½å®Œæˆï¼

ğŸ“Š é è¦½çµ±è¨ˆ:
  - è³‡æ–™å¤¾: {folder_path}
  - ç¸½å½±ç‰‡æ•¸: {preview_results['total_videos']}
  - é è¦½å½±ç‰‡æ•¸: {preview_results['sampled_videos']}
  - æª¢æ¸¬å…§å®¹é¡å‹: {preview_results.get('detected_content_type', 'unknown')}
  - ä¸€è‡´æ€§ä¿¡å¿ƒåº¦: {preview_results['confidence_score']:.2f}

ğŸ¯ æ¨è–¦è™•ç†æ¨¡å¼: {preview_results['recommended_mode']}

ğŸ“‹ é è¦½åˆ†æçµæœ:"""
        
        for analysis in preview_results["content_analysis"]:
            confidence = analysis.get("confidence", 0.0)
            content_type = analysis.get("content_type", "unknown")
            response_text += f"\n  - {analysis['filename']}: {content_type} (ä¿¡å¿ƒåº¦: {confidence:.2f})"
        
        if preview_results["recommended_mode"] == "auto":
            response_text += "\n\nâœ… å»ºè­°ä½¿ç”¨è‡ªå‹•æ¨¡å¼ (è·¯å¾‘A) - å…§å®¹é¡å‹ä¸€è‡´ä¸”ç¬¦åˆé æœŸ"
        elif preview_results["recommended_mode"] == "guided":
            response_text += "\n\nâš ï¸ å»ºè­°ä½¿ç”¨å¼•å°æ¨¡å¼ (è·¯å¾‘B) - å…§å®¹é¡å‹ä¸ç¢ºå®šï¼Œéœ€è¦ç”¨æˆ¶ç¢ºèª"
        else:
            response_text += "\n\nğŸ”„ å»ºè­°ä½¿ç”¨é€šç”¨æ¨¡å¼ (è·¯å¾‘C) - å…§å®¹é¡å‹è¤‡é›œï¼Œä½¿ç”¨é€šç”¨åˆ†æ"
        
        return [
            types.TextContent(
                type="text",
                text=response_text
            )
        ]
        
    except Exception as e:
        logger.error(f"Smart preview error: {e}")
        return [
            types.TextContent(
                type="text",
                text=f"âŒ æ™ºèƒ½é è¦½å¤±æ•—: {str(e)}"
            )
        ]

async def parallel_analysis_tool(arguments: dict) -> list[types.TextContent]:
    """ä¸¦è¡Œè·¯å¾‘è™•ç†å™¨ - çµ±ä¸€è·¯å¾‘A/B/Cçš„æ™ºèƒ½åˆ†æèˆ‡ç”¨æˆ¶å¼•å°ä»‹é¢"""
    folder_path = arguments["folder_path"]
    processing_mode = arguments.get("processing_mode", "auto")
    group_size = arguments.get("group_size", 3)
    cost_limit = arguments.get("cost_limit", 5.0)
    interactive_mode = arguments.get("interactive_mode", True)
    
    try:
        # æƒæå½±ç‰‡æª”æ¡ˆ
        import glob
        video_files = []
        for ext in ["*.MOV", "*.mp4", "*.mov", "*.avi", "*.mkv", "*.webm"]:
            video_files.extend(glob.glob(os.path.join(folder_path, ext)))
        
        if not video_files:
            return [
                types.TextContent(
                    type="text",
                    text=f"âŒ æœªåœ¨ {folder_path} æ‰¾åˆ°å½±ç‰‡æª”æ¡ˆ"
                )
            ]
        
        # è¨ˆç®—åˆ†çµ„
        total_groups = (len(video_files) + group_size - 1) // group_size
        
        # æˆæœ¬ä¼°ç®—
        estimated_cost_per_video = 0.15  # åŸºæ–¼æ­·å²æ•¸æ“š
        total_estimated_cost = len(video_files) * estimated_cost_per_video
        
        # æª¢æŸ¥æˆæœ¬é™åˆ¶
        if total_estimated_cost > cost_limit:
            return [
                types.TextContent(
                    type="text",
                    text=f"""ğŸ’° æˆæœ¬è­¦å‘Šï¼

é ä¼°ç¸½æˆæœ¬: ${total_estimated_cost:.2f} USD
è¨­å®šä¸Šé™: ${cost_limit:.2f} USD

å»ºè­°èª¿æ•´:
1. æ¸›å°‘å½±ç‰‡æ•¸é‡ï¼šè™•ç†å‰ {int(cost_limit / estimated_cost_per_video)} å€‹å½±ç‰‡
2. æé«˜æˆæœ¬ä¸Šé™
3. ä½¿ç”¨å…è²»æ¨¡å‹ (å“è³ªè¼ƒä½ä½†æˆæœ¬ç‚ºé›¶)

æ˜¯å¦ç¹¼çºŒè™•ç†ï¼Ÿè«‹èª¿æ•´åƒæ•¸å¾Œé‡æ–°åŸ·è¡Œã€‚"""
                )
            ]
        
        # è·¯å¾‘A: è‡ªå‹•æ¨¡å¼
        if processing_mode == "auto":
            # ç›´æ¥ä½¿ç”¨ç¾æœ‰çš„æ‰¹é‡åˆ†æå·¥å…·ï¼Œä½†åŠ å…¥åˆ†çµ„å’Œé€²åº¦è¿½è¹¤
            result = await batch_video_script_analysis_tool({
                "folder_path": folder_path,
                "output_filename": f"parallel_analysis_auto_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                "analysis_detail": "comprehensive",
                "include_technical_analysis": True,
                "max_concurrent_videos": group_size
            })
            
            return [
                types.TextContent(
                    type="text",
                    text=f"ğŸ¤– è·¯å¾‘A - è‡ªå‹•æ¨¡å¼å®Œæˆ\n\n{result[0].text}"
                )
            ]
        
        # è·¯å¾‘B: å¼•å°æ¨¡å¼
        elif processing_mode == "guided":
            response_text = f"""ğŸ¯ è·¯å¾‘B - å¼•å°æ¨¡å¼å•Ÿå‹•

ğŸ“‹ è™•ç†è¨ˆåŠƒ:
  - ç¸½å½±ç‰‡æ•¸: {len(video_files)}
  - åˆ†çµ„æ•¸é‡: {total_groups}
  - æ¯çµ„å½±ç‰‡æ•¸: {group_size}
  - é ä¼°æˆæœ¬: ${total_estimated_cost:.2f} USD

ğŸ¬ å½±ç‰‡æ¸…å–®é è¦½:"""
            
            for i, video_file in enumerate(video_files[:10]):  # é¡¯ç¤ºå‰10å€‹
                file_size = os.path.getsize(video_file) / (1024*1024)
                response_text += f"\n  {i+1}. {os.path.basename(video_file)} ({file_size:.1f}MB)"
            
            if len(video_files) > 10:
                response_text += f"\n  ... é‚„æœ‰ {len(video_files) - 10} å€‹æª”æ¡ˆ"
            
            response_text += f"""

ğŸ”§ å¯é¸è™•ç†åƒæ•¸:
  - åˆ†æç­‰ç´š: comprehensive (æ¨è–¦)
  - æŠ€è¡“åˆ†æ: å•Ÿç”¨
  - ç„¡äººæ©Ÿå°ˆé …: å•Ÿç”¨

è«‹ç¢ºèªæ˜¯å¦é–‹å§‹åˆ†çµ„è™•ç†ï¼Ÿ
ä¸‹ä¸€æ­¥å°‡å‰µå»ºè©³ç´°çš„åŸ·è¡Œè¨ˆåŠƒã€‚"""
            
            return [
                types.TextContent(
                    type="text",
                    text=response_text
                )
            ]
        
        # è·¯å¾‘C: é€šç”¨æ¨¡å¼
        else:  # universal
            # ä½¿ç”¨ä¿å®ˆçš„é€šç”¨è¨­å®š
            result = await batch_video_script_analysis_tool({
                "folder_path": folder_path,
                "output_filename": f"parallel_analysis_universal_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                "analysis_detail": "detailed",  # é™ä½ä¸€ç´šä»¥æ¸›å°‘æˆæœ¬
                "include_technical_analysis": False,  # é—œé–‰æŠ€è¡“åˆ†æ
                "max_concurrent_videos": 2  # é™ä½ä¸¦ç™¼æ•¸
            })
            
            return [
                types.TextContent(
                    type="text",
                    text=f"ğŸ”„ è·¯å¾‘C - é€šç”¨æ¨¡å¼å®Œæˆ\n\n{result[0].text}"
                )
            ]
    
    except Exception as e:
        logger.error(f"Parallel analysis error: {e}")
        return [
            types.TextContent(
                type="text",
                text=f"âŒ ä¸¦è¡Œåˆ†æå¤±æ•—: {str(e)}"
            )
        ]

async def analyze_single_video(video_path: str, analysis_prompt: str) -> dict:
    """åˆ†æå–®å€‹å½±ç‰‡æª”æ¡ˆ"""
    try:
        # ä¸Šå‚³å½±ç‰‡åˆ° Gemini
        video_file = genai.upload_file(path=video_path)
        logger.info(f"Uploaded video: {video_file.name}")
        
        # ç­‰å¾…è™•ç†å®Œæˆ
        while video_file.state.name == "PROCESSING":
            await asyncio.sleep(1)
            video_file = genai.get_file(video_file.name)
        
        if video_file.state.name == "FAILED":
            raise Exception(f"Video processing failed: {video_file.state.name}")
        
        # ç”Ÿæˆåˆ†æå…§å®¹
        response = model.generate_content([video_file, analysis_prompt])
        
        # æ¸…ç†ä¸Šå‚³çš„æª”æ¡ˆ
        genai.delete_file(video_file.name)
        
        # ä½¿ç”¨æ™ºèƒ½JSONæå–å™¨è§£æå›æ‡‰
        from .json_extractor import IntelligentJSONExtractor
        
        extractor = IntelligentJSONExtractor()
        result = extractor.extract_json_from_response(response.text)
        
        # æ·»åŠ è™•ç†å…ƒæ•¸æ“š
        if "_metadata" not in result:
            result["_metadata"] = {}
        result["_metadata"]["video_file"] = video_path
        result["_metadata"]["analysis_timestamp"] = datetime.now().isoformat()
        
        return result
            
    except Exception as e:
        logger.error(f"Error analyzing video {video_path}: {e}")
        raise

async def main():
    """ä¸»å‡½æ•¸"""
    # è¨­ç½®èªè­‰
    setup_authentication()
    
    # ä½¿ç”¨ stdio ä¼ºæœå™¨
    async with mcp.server.stdio.stdio_server() as (read_stream, write_stream):
        await server.run(
            read_stream,
            write_stream,
            InitializationOptions(
                server_name="gemini-mcp-server",
                server_version="1.0.0",
                capabilities=server.get_capabilities(
                    notification_options=NotificationOptions(),
                    experimental_capabilities={},
                )
            )
        )

if __name__ == "__main__":
    try:
        logger.info("Starting Gemini MCP Server...")
        asyncio.run(main())
    except KeyboardInterrupt:
        logger.info("Server stopped by user")
    except Exception as e:
        logger.error(f"Server error: {e}")
        sys.exit(1)