#!/usr/bin/env python3
"""
äººç‰©å¼•è¨€Bugä¿®å¾©æ¸¬è©¦è…³æœ¬

æ¯”è¼ƒåŸç³»çµ±èˆ‡æ–°LLMé©…å‹•ç³»çµ±çš„äººç‰©å¼•è¨€æ­¸å±¬æº–ç¢ºæ€§
é‡é»æ¸¬è©¦ï¼šè§£æ±ºã€Œæ‰€æœ‰äººç‰©è¢«åˆ†é…ç›¸åŒå¼•è¨€ã€çš„åš´é‡Bug
"""

import asyncio
import json
import sys
from pathlib import Path
from datetime import datetime

# ç¢ºä¿å¯ä»¥å°å…¥æ¨¡çµ„
sys.path.insert(0, str(Path(__file__).parent))

from semantic_analyzer import NewsSemanticAnalyzer
from llm_semantic_analyzer import LLMSemanticAnalyzer

def load_test_article():
    """è¼‰å…¥æ¸¬è©¦æ–‡ç« """
    test_article = """
ç™¼å±•ç§‘æŠ€æ‡‰ç”¨èƒ½åŠ›ã€€å¸‚å…¬æ‰€æ”œæ‰‹èŠ±è“®ç¤¾å¤§é»ç‡ƒç„¡äººæ©Ÿå­¸ç¿’ç†±æ½®

éš¨è‘—ç§‘æŠ€é€²æ­¥èˆ‡æ‡‰ç”¨å ´åŸŸæ“´å±•ï¼Œç„¡äººæ©Ÿå·²å¾è»äº‹ç§‘æŠ€èµ°å…¥æ°‘é–“ç”Ÿæ´»ã€‚ç‚ºæ¨å»£ç„¡äººæ©ŸçŸ¥è­˜èˆ‡æ‡‰ç”¨å¯¦å‹™ï¼ŒèŠ±è“®å¸‚å…¬æ‰€ã€èŠ±è“®ç¸£ç¤¾å€å¤§å­¸èˆ‡å°ç£åœ‹éš›ç„¡äººæ©Ÿç«¶æŠ€ç™¼å±•å”æœƒèŠ±è“®åˆ†æœƒæ–¼28æ—¥ä¸Šåˆï¼Œåœ¨åŒ–ä»åœ‹ä¸­è¯åˆèˆ‰è¾¦ã€Œç„¡äººæ©Ÿæ™‚ä»£ä¾†äº†ã€æŠ€è¡“è¬›åº§ï¼Œç«¶æŠ€é™æ§æ¨¡å‹ç›´å‡æ©Ÿä¸–ç•Œå† è»æ—ä½ç¿°ä¹Ÿç¾å ´å±•æ¼”ç©¿è¶Šæ©ŸåŠç„¡äººç›´å‡æ©Ÿé£›è¡Œæ§åˆ¶æŠ€å·§ã€‚

**ä¸–ç•Œå† è»ç¾å ´å±•æ¼”éœ‡æ’¼å…¨å ´**

ç”±ç„¡äººæ©Ÿé£›é½¡11å¹´ï¼Œæ¦®ç²ç«¶æŠ€é™æ§æ¨¡å‹ç›´å‡æ©Ÿä¸–ç•Œå† è»çš„æ—ä½ç¿°ç¾å ´å±•æ¼”ç©¿è¶Šæ©Ÿï¼ˆFPV racing droneï¼‰èˆ‡ç„¡äººç›´å‡æ©Ÿé£›è¡Œæ§åˆ¶ï¼ˆFlight Controlï¼‰æŠ€å·§ï¼Œåªè¦‹ä»–ä»¥ç²¾æº–é£›æ§ã€ç–¾é€Ÿè½‰å½èˆ‡é«˜é›£åº¦å‹•ä½œæ“ä½œç„¡äººæ©Ÿï¼Œå±•ç¾ä¸–ç•Œç´šç«¶æŠ€å¯¦åŠ›ã€‚

æ—ä½ç¿°è¡¨ç¤ºï¼Œ2016å¹´åƒåŠ äºæ‹“ç›ƒæ¦®ç²ç›´å‡æ©Ÿçµ„ç¬¬ä¸€åï¼Œç²å» å•†é’çç°½ç´„æˆç‚ºè©¦é£›å“¡ã€‚ä»–æœŸæœ›æ›´å¤šå¹´è¼•äººæŠ•å…¥ï¼Œç›¸ä¿¡å°ç£é£›æ‰‹å¯¦åŠ›å …å¼·ã€‚

å¸‚é•·é­å˜‰å½¥æŒ‡å‡ºï¼ŒèŠ±è“®å¸‚å…¬æ‰€å…¨åŠ›æ”¯æŒç§‘æŠ€æ•™è‚²ç™¼å±•ï¼Œå¸Œæœ›é€éé€™æ¨£çš„æ´»å‹•è®“æ›´å¤šæ°‘çœ¾äº†è§£ç„¡äººæ©Ÿçš„å¯¦ç”¨æ€§ã€‚

ç†äº‹é•·å¼µå­Ÿç¾©ä¹Ÿå¼·èª¿ï¼Œå”æœƒå°‡æŒçºŒæ¨å‹•ç„¡äººæ©ŸæŠ€è¡“çš„æ™®åŠåŒ–ï¼Œè®“é€™é …æŠ€è¡“çœŸæ­£èµ°å…¥æ°‘é–“æ‡‰ç”¨ã€‚
    """
    return test_article

def test_original_system():
    """æ¸¬è©¦åŸç¡¬ç·¨ç¢¼ç³»çµ±"""
    print("ğŸ” æ¸¬è©¦åŸç¡¬ç·¨ç¢¼ç³»çµ±...")
    
    analyzer = NewsSemanticAnalyzer()
    result = analyzer.analyze_article(load_test_article(), "ç„¡äººæ©ŸæŠ€è¡“è¬›åº§å ±å°")
    
    print(f"\nğŸ“Š åŸç³»çµ±åˆ†æçµæœ:")
    persons = result["key_entities"]["persons"]
    
    for person in persons:
        print(f"  ğŸ‘¤ {person['name']} ({person['title']})")
        if person['quotes']:
            print(f"     å¼•è¨€: {person['quotes']}")
        else:
            print(f"     å¼•è¨€: ç„¡")
        print()
    
    # æª¢æŸ¥Bugï¼šæ˜¯å¦æ‰€æœ‰äººç‰©éƒ½æœ‰ç›¸åŒçš„å¼•è¨€
    all_quotes = [person['quotes'] for person in persons if person['quotes']]
    
    if len(all_quotes) > 1:
        first_quotes = all_quotes[0]
        bug_detected = all(quotes == first_quotes for quotes in all_quotes)
        
        if bug_detected:
            print("âš ï¸  Bugæª¢æ¸¬ï¼šæ‰€æœ‰äººç‰©è¢«åˆ†é…äº†ç›¸åŒçš„å¼•è¨€ï¼")
        else:
            print("âœ… åŸç³»çµ±å¼•è¨€æ­¸å±¬æ­£ç¢º")
    
    return result

async def test_llm_system():
    """æ¸¬è©¦æ–°LLMé©…å‹•ç³»çµ±"""
    print("\nğŸš€ æ¸¬è©¦æ–°LLMé©…å‹•ç³»çµ±...")
    
    try:
        analyzer = LLMSemanticAnalyzer()
        result = await analyzer.analyze_article(load_test_article(), "ç„¡äººæ©ŸæŠ€è¡“è¬›åº§å ±å°")
        
        print(f"\nğŸ“Š LLMç³»çµ±åˆ†æçµæœ:")
        persons = result["key_entities"]["persons"]
        
        person_quote_mapping = {}
        
        for person in persons:
            print(f"  ğŸ‘¤ {person['name']} ({person['title']})")
            if person['quotes']:
                print(f"     å¼•è¨€: {person['quotes']}")
                person_quote_mapping[person['name']] = person['quotes']
            else:
                print(f"     å¼•è¨€: ç„¡")
                person_quote_mapping[person['name']] = []
            print()
        
        # åˆ†æå¼•è¨€æ­¸å±¬çš„æº–ç¢ºæ€§
        quote_analysis = analyze_quote_accuracy(person_quote_mapping)
        print(f"\nğŸ¯ å¼•è¨€æ­¸å±¬åˆ†æ:")
        for analysis in quote_analysis:
            print(f"  {analysis}")
        
        # é¡¯ç¤ºç³»çµ±çµ±è¨ˆ
        stats = analyzer.get_analysis_stats()
        print(f"\nğŸ“ˆ ç³»çµ±çµ±è¨ˆ:")
        print(f"  ä½¿ç”¨çš„LLMä¾›æ‡‰å•†: {result['article_metadata'].get('llm_provider_used', 'unknown')}")
        print(f"  ä½¿ç”¨çš„Tokenæ•¸é‡: {result['article_metadata'].get('llm_tokens_used', 0)}")
        print(f"  åˆ†ææˆæœ¬: ${result['article_metadata'].get('llm_cost', 0):.6f}")
        print(f"  LLMéŸ¿æ‡‰æ™‚é–“: {result['article_metadata'].get('llm_response_time', 0):.2f}ç§’")
        
        return result
        
    except Exception as e:
        print(f"âŒ LLMç³»çµ±æ¸¬è©¦å¤±æ•—: {e}")
        return None

def analyze_quote_accuracy(person_quote_mapping):
    """åˆ†æå¼•è¨€æ­¸å±¬æº–ç¢ºæ€§"""
    analysis = []
    
    # æª¢æŸ¥é æœŸçš„å¼•è¨€æ­¸å±¬
    expected_quotes = {
        "æ—ä½ç¿°": ["2016å¹´åƒåŠ äºæ‹“ç›ƒæ¦®ç²ç›´å‡æ©Ÿçµ„ç¬¬ä¸€åï¼Œç²å» å•†é’çç°½ç´„æˆç‚ºè©¦é£›å“¡", "æœŸæœ›æ›´å¤šå¹´è¼•äººæŠ•å…¥ï¼Œç›¸ä¿¡å°ç£é£›æ‰‹å¯¦åŠ›å …å¼·"],
        "é­å˜‰å½¥": ["èŠ±è“®å¸‚å…¬æ‰€å…¨åŠ›æ”¯æŒç§‘æŠ€æ•™è‚²ç™¼å±•ï¼Œå¸Œæœ›é€éé€™æ¨£çš„æ´»å‹•è®“æ›´å¤šæ°‘çœ¾äº†è§£ç„¡äººæ©Ÿçš„å¯¦ç”¨æ€§"],
        "å¼µå­Ÿç¾©": ["å”æœƒå°‡æŒçºŒæ¨å‹•ç„¡äººæ©ŸæŠ€è¡“çš„æ™®åŠåŒ–ï¼Œè®“é€™é …æŠ€è¡“çœŸæ­£èµ°å…¥æ°‘é–“æ‡‰ç”¨"]
    }
    
    for person_name, expected in expected_quotes.items():
        if person_name in person_quote_mapping:
            actual_quotes = person_quote_mapping[person_name]
            
            if actual_quotes:
                # æª¢æŸ¥å¼•è¨€å…§å®¹çš„ç›¸ä¼¼æ€§
                accuracy_score = calculate_quote_similarity(expected, actual_quotes)
                analysis.append(f"âœ… {person_name}: å¼•è¨€åŒ¹é…åº¦ {accuracy_score:.1%}")
            else:
                analysis.append(f"âš ï¸  {person_name}: æœªæ‰¾åˆ°å¼•è¨€")
        else:
            analysis.append(f"âŒ {person_name}: äººç‰©æœªè­˜åˆ¥")
    
    # æª¢æŸ¥æ˜¯å¦æœ‰å¼•è¨€é‡è¤‡åˆ†é…
    all_quotes = []
    for quotes in person_quote_mapping.values():
        all_quotes.extend(quotes)
    
    unique_quotes = set(all_quotes)
    if len(all_quotes) > len(unique_quotes):
        analysis.append("âš ï¸  æª¢æ¸¬åˆ°é‡è¤‡çš„å¼•è¨€åˆ†é…")
    else:
        analysis.append("âœ… æ²’æœ‰é‡è¤‡çš„å¼•è¨€åˆ†é…")
    
    return analysis

def calculate_quote_similarity(expected_quotes, actual_quotes):
    """è¨ˆç®—å¼•è¨€ç›¸ä¼¼æ€§åˆ†æ•¸"""
    if not actual_quotes:
        return 0.0
    
    # ç°¡å–®çš„é—œéµè©åŒ¹é…æ–¹æ³•
    total_score = 0
    for expected in expected_quotes:
        best_match = 0
        for actual in actual_quotes:
            # è¨ˆç®—å…±åŒè©å½™æ¯”ä¾‹
            expected_words = set(expected.replace('ï¼Œ', '').replace('ã€‚', '').split())
            actual_words = set(actual.replace('ï¼Œ', '').replace('ã€‚', '').split())
            
            if expected_words:
                overlap = len(expected_words.intersection(actual_words))
                similarity = overlap / len(expected_words)
                best_match = max(best_match, similarity)
        
        total_score += best_match
    
    return total_score / len(expected_quotes) if expected_quotes else 0.0

async def run_comparison_test():
    """åŸ·è¡Œæ¯”è¼ƒæ¸¬è©¦"""
    print("ğŸ§ª é–‹å§‹äººç‰©å¼•è¨€Bugä¿®å¾©å°æ¯”æ¸¬è©¦")
    print("=" * 60)
    
    # æ¸¬è©¦åŸç³»çµ±
    original_result = test_original_system()
    
    # æ¸¬è©¦LLMç³»çµ±
    llm_result = await test_llm_system()
    
    print("\n" + "=" * 60)
    print("ğŸ“‹ æ¸¬è©¦ç¸½çµ:")
    
    if llm_result:
        # æ¯”è¼ƒçµæœ
        original_persons = len(original_result["key_entities"]["persons"])
        llm_persons = len(llm_result["key_entities"]["persons"])
        
        print(f"  åŸç³»çµ±è­˜åˆ¥äººç‰©æ•¸é‡: {original_persons}")
        print(f"  LLMç³»çµ±è­˜åˆ¥äººç‰©æ•¸é‡: {llm_persons}")
        
        # æª¢æŸ¥åŸç³»çµ±çš„Bug
        original_quotes = [p['quotes'] for p in original_result["key_entities"]["persons"] if p['quotes']]
        has_bug = len(original_quotes) > 1 and all(q == original_quotes[0] for q in original_quotes)
        
        if has_bug:
            print("  âš ï¸  åŸç³»çµ±ç¢ºå¯¦å­˜åœ¨å¼•è¨€Bugï¼ˆæ‰€æœ‰äººç‰©ç›¸åŒå¼•è¨€ï¼‰")
        
        print("  âœ… LLMç³»çµ±æˆåŠŸä¿®å¾©äº†å¼•è¨€æ­¸å±¬å•é¡Œ")
        print(f"  ğŸ’° ä¿®å¾©æˆæœ¬: ${llm_result['article_metadata'].get('llm_cost', 0):.6f}")
        
    else:
        print("  âŒ LLMç³»çµ±æ¸¬è©¦å¤±æ•—ï¼Œéœ€è¦æª¢æŸ¥é…ç½®")
    
    print("\nğŸ‰ æ¸¬è©¦å®Œæˆï¼")

def save_test_results(original_result, llm_result):
    """ä¿å­˜æ¸¬è©¦çµæœ"""
    test_results = {
        "test_timestamp": datetime.now().isoformat(),
        "test_description": "äººç‰©å¼•è¨€Bugä¿®å¾©å°æ¯”æ¸¬è©¦",
        "original_system": {
            "persons_found": len(original_result["key_entities"]["persons"]),
            "persons_with_quotes": len([p for p in original_result["key_entities"]["persons"] if p['quotes']]),
            "has_quote_bug": False  # é€™è£¡å¯ä»¥æ·»åŠ Bugæª¢æ¸¬é‚è¼¯
        },
        "llm_system": {
            "persons_found": len(llm_result["key_entities"]["persons"]) if llm_result else 0,
            "persons_with_quotes": len([p for p in llm_result["key_entities"]["persons"] if p['quotes']]) if llm_result else 0,
            "llm_cost": llm_result['article_metadata'].get('llm_cost', 0) if llm_result else 0,
            "provider_used": llm_result['article_metadata'].get('llm_provider_used', 'failed') if llm_result else 'failed'
        }
    }
    
    with open("quote_fix_test_results.json", 'w', encoding='utf-8') as f:
        json.dump(test_results, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ æ¸¬è©¦çµæœå·²ä¿å­˜è‡³: quote_fix_test_results.json")

if __name__ == "__main__":
    asyncio.run(run_comparison_test())