#!/usr/bin/env python3
"""
æç¤ºè©æ¨¡æ¿ç®¡ç†å™¨ - BigDipper AIå‰ªè¼¯ç³»çµ±

ä¸»é¡Œè‡ªé©æ‡‰æç¤ºè©æ¨¡æ¿ç³»çµ±ï¼Œæ”¯æ´ï¼š
- å‹•æ…‹èªç¾©åˆ†ææç¤ºè©
- XMLçµæ§‹åŒ–è¼¸å‡ºè¦ç¯„
- äººç‰©å¼•è¨€ç²¾ç¢ºåŒ¹é…
- ä¸»é¡Œç‰¹å®šåˆ†æå„ªåŒ–
- å¤šå±¤æ¬¡é—œéµè©ç”Ÿæˆ
"""

from typing import Dict, List, Optional, Any
from enum import Enum
import logging

logger = logging.getLogger("prompt_templates")

class ArticleType(Enum):
    """æ–‡ç« é¡å‹æšèˆ‰"""
    TECHNOLOGY = "technology"      # ç§‘æŠ€æ–°è
    POLITICS = "politics"          # æ”¿æ²»æ–°è  
    BUSINESS = "business"          # å•†æ¥­æ–°è
    SPORTS = "sports"              # é«”è‚²æ–°è
    ENTERTAINMENT = "entertainment" # å¨›æ¨‚æ–°è
    EDUCATION = "education"        # æ•™è‚²æ–°è
    GENERAL = "general"            # ä¸€èˆ¬æ–°è

class PromptTemplateManager:
    """ä¸»é¡Œè‡ªé©æ‡‰æç¤ºè©æ¨¡æ¿ç®¡ç†å™¨"""
    
    def __init__(self):
        self.base_xml_schema = self._get_base_xml_schema()
        self.semantic_analysis_templates = self._init_semantic_templates()
        self.quote_extraction_templates = self._init_quote_templates()
        self.keyword_generation_templates = self._init_keyword_templates()
        self.topic_specific_contexts = self._init_topic_contexts()
    
    def _get_base_xml_schema(self) -> str:
        """åŸºç¤XMLè¼¸å‡ºçµæ§‹è¦ç¯„"""
        return """
<semantic_analysis>
    <metadata>
        <article_type>{article_type}</article_type>
        <main_topic>{main_topic}</main_topic>
        <processing_timestamp>{timestamp}</processing_timestamp>
    </metadata>
    
    <entities>
        <persons>
            <!-- æ¯å€‹äººç‰©å–®ç¨åˆ—å‡ºï¼Œç¢ºä¿å¼•è¨€æ­£ç¢ºæ­¸å±¬ -->
            <person name="å§“å" title="è·ç¨±" role="è§’è‰²é¡å‹">
                <quotes>
                    <quote>å¯¦éš›å¼•è¨€å…§å®¹1</quote>
                    <quote>å¯¦éš›å¼•è¨€å…§å®¹2</quote>
                </quotes>
                <expertise>å°ˆæ¥­é ˜åŸŸ1,å°ˆæ¥­é ˜åŸŸ2</expertise>
            </person>
        </persons>
        
        <organizations>
            <org name="çµ„ç¹”åç¨±" type="é¡å‹" importance="high/medium/low"/>
        </organizations>
        
        <locations>
            <location name="åœ°é»åç¨±" type="city/country/venue" relevance="æ ¸å¿ƒ/æ¬¡è¦"/>
        </locations>
        
        <events>
            <event name="äº‹ä»¶åç¨±" type="é¡å‹" impact_level="1-10" timeframe="æ™‚é–“ç¯„åœ"/>
        </events>
    </entities>
    
    <content_analysis>
        <main_themes>
            <theme name="ä¸»é¡Œåç¨±" relevance_score="0.0-1.0" keywords="é—œéµè©åˆ—è¡¨"/>
        </main_themes>
        
        <sentiment_analysis>
            <overall sentiment="positive/negative/neutral" confidence="0.0-1.0" intensity="1-10"/>
            <by_paragraph>
                <paragraph id="1" sentiment="positive/negative/neutral" score="0.0-1.0" key_emotions="æƒ…æ„Ÿè©å½™"/>
            </by_paragraph>
        </sentiment_analysis>
        
        <narrative_structure>
            <section type="introduction" paragraphs="1-2" purpose="å¼•è¨€èªªæ˜"/>
            <section type="development" paragraphs="3-5" purpose="äº‹ä»¶ç™¼å±•"/>
            <section type="climax" paragraphs="6-7" purpose="é«˜æ½®é‡é»"/>
            <section type="conclusion" paragraphs="8-9" purpose="çµè«–å±•æœ›"/>
        </narrative_structure>
        
        <technical_concepts>
            <concept name="æŠ€è¡“æ¦‚å¿µ" description="æè¿°" importance="1-10" applications="æ‡‰ç”¨é ˜åŸŸ"/>
        </technical_concepts>
    </content_analysis>
    
    <editing_intelligence>
        <primary_cues>
            <cue type="visual" description="è¦–è¦ºé‡é»" timing="å»ºè­°æ™‚æ©Ÿ"/>
        </primary_cues>
        
        <secondary_cues>
            <cue type="audio" description="éŸ³é »é‡é»" emphasis="å¼·èª¿ç¨‹åº¦"/>
        </secondary_cues>
        
        <pacing_suggestions>
            <suggestion segment="æ®µè½ç¯„åœ" pace="å¿«/ä¸­/æ…¢" reason="ç¯€å¥åŸå› "/>
        </pacing_suggestions>
        
        <visual_requirements>
            <requirement type="scene_type" description="å ´æ™¯éœ€æ±‚" priority="high/medium/low"/>
        </visual_requirements>
    </editing_intelligence>
    
    <semantic_vectors>
        <content_keywords>å‹•æ…‹ç”Ÿæˆçš„å…§å®¹é—œéµè©</content_keywords>
        <technical_keywords>æŠ€è¡“ç›¸é—œé—œéµè©</technical_keywords>
        <action_keywords>å‹•ä½œæè¿°é—œéµè©</action_keywords>
        <emotion_keywords>æƒ…æ„Ÿè¡¨é”é—œéµè©</emotion_keywords>
    </semantic_vectors>
</semantic_analysis>
"""
    
    def _init_semantic_templates(self) -> Dict[ArticleType, str]:
        """åˆå§‹åŒ–èªç¾©åˆ†ææ¨¡æ¿"""
        templates = {}
        
        # ç§‘æŠ€æ–°èæ¨¡æ¿
        templates[ArticleType.TECHNOLOGY] = """
ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„ç§‘æŠ€æ–°èèªç¾©åˆ†æå°ˆå®¶ã€‚è«‹ä»”ç´°åˆ†æä»¥ä¸‹ç§‘æŠ€æ–°èæ–‡ç« ï¼Œç‰¹åˆ¥é—œæ³¨ï¼š

ğŸ” **åˆ†æé‡é»**ï¼š
- æŠ€è¡“æ¦‚å¿µå’Œå‰µæ–°é»
- å°ˆå®¶è§€é»å’ŒæŠ€è¡“è©•ä¼°
- ç”¢æ¥­è¶¨å‹¢å’Œæ‡‰ç”¨å ´æ™¯
- æŠ€è¡“æ¼”ç¤ºå’Œå¯¦éš›æ•ˆæœ

âš ï¸ **é‡è¦æé†’**ï¼š
1. äººç‰©å¼•è¨€å¿…é ˆç²¾ç¢ºåŒ¹é…ï¼Œæ¯å€‹äººçš„å¯¦éš›è©±èªå…§å®¹
2. æŠ€è¡“è¡“èªéœ€è¦æº–ç¢ºè­˜åˆ¥å’Œè§£é‡‹
3. æ³¨æ„å€åˆ†æŠ€è¡“æ¦‚å¿µçš„é‡è¦æ€§ç­‰ç´š
4. è­˜åˆ¥å‰µæ–°æ€§å’Œå¯¦ç”¨æ€§ç‰¹å¾µ

ğŸ“‹ **è¼¸å‡ºè¦æ±‚**ï¼š
è«‹åš´æ ¼æŒ‰ç…§ä»¥ä¸‹XMLæ ¼å¼è¼¸å‡ºåˆ†æçµæœï¼š

{xml_schema}

ğŸ“„ **å¾…åˆ†ææ–‡ç« **ï¼š
{content}

è«‹ç¢ºä¿ï¼š
- æ‰€æœ‰äººç‰©å¼•è¨€éƒ½æº–ç¢ºæ­¸å±¬
- æŠ€è¡“æ¦‚å¿µæŒ‰é‡è¦æ€§æ’åº
- è¦–è¦ºéœ€æ±‚å…·é«”æ˜ç¢º
- å‰ªè¼¯å»ºè­°ç¬¦åˆç§‘æŠ€ä¸»é¡Œç‰¹é»
"""
        
        # ä¸€èˆ¬æ–°èæ¨¡æ¿
        templates[ArticleType.GENERAL] = """
ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„æ–°èèªç¾©åˆ†æå°ˆå®¶ã€‚è«‹ä»”ç´°åˆ†æä»¥ä¸‹æ–°èæ–‡ç« ï¼Œæå–æ‰€æœ‰é—œéµä¿¡æ¯ï¼š

ğŸ” **åˆ†æé‡é»**ï¼š
- é—œéµäººç‰©åŠå…¶è§€é»ç«‹å ´
- é‡è¦äº‹ä»¶å’Œæ™‚é–“ç·š
- ä¸»è¦çµ„ç¹”æ©Ÿæ§‹
- æƒ…æ„Ÿè‰²å½©å’Œæ•˜äº‹çµæ§‹

âš ï¸ **é‡è¦æé†’**ï¼š
1. äººç‰©å¼•è¨€å¿…é ˆç²¾ç¢ºåŒ¹é…ï¼Œé¿å…æ··æ·†ä¸åŒäººç‰©çš„è©±èª
2. ç¢ºä¿æ‰€æœ‰å¯¦é«”ä¿¡æ¯æº–ç¢ºæå–
3. æƒ…æ„Ÿåˆ†æè¦å®¢è§€ä¸­æ€§
4. æ•˜äº‹çµæ§‹è¦ç¬¦åˆæ–°èç‰¹é»

ğŸ“‹ **è¼¸å‡ºè¦æ±‚**ï¼š
è«‹åš´æ ¼æŒ‰ç…§ä»¥ä¸‹XMLæ ¼å¼è¼¸å‡ºåˆ†æçµæœï¼š

{xml_schema}

ğŸ“„ **å¾…åˆ†ææ–‡ç« **ï¼š
{content}

è«‹ç¢ºä¿ï¼š
- äººç‰©-å¼•è¨€å°æ‡‰é—œä¿‚100%æº–ç¢º
- çµ„ç¹”æ©Ÿæ§‹é¡å‹æ­£ç¢ºæ¨™è¨»
- äº‹ä»¶æ™‚é–“ç·šæ¸…æ™°
- å‰ªè¼¯å»ºè­°å¯¦ç”¨å¯è¡Œ
"""
        
        # å•†æ¥­æ–°èæ¨¡æ¿
        templates[ArticleType.BUSINESS] = """
ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„å•†æ¥­æ–°èèªç¾©åˆ†æå°ˆå®¶ã€‚è«‹åˆ†æä»¥ä¸‹å•†æ¥­æ–°èï¼Œé‡é»é—œæ³¨ï¼š

ğŸ” **åˆ†æé‡é»**ï¼š
- å•†æ¥­æ±ºç­–å’Œç­–ç•¥æ–¹å‘
- å¸‚å ´è¶¨å‹¢å’Œè²¡å‹™æ•¸æ“š
- ä¼æ¥­é ˜å°äººè§€é»
- ç«¶çˆ­æ…‹å‹¢å’Œå½±éŸ¿åˆ†æ

âš ï¸ **é‡è¦æé†’**ï¼š
1. æº–ç¢ºå€åˆ†ä¸åŒä¼æ¥­é«˜ç®¡çš„è§€é»
2. æ³¨æ„è²¡å‹™æ•¸æ“šå’Œå¸‚å ´é æ¸¬
3. è­˜åˆ¥å•†æ¥­æ¨¡å¼å’Œç­–ç•¥å‰µæ–°
4. åˆ†æå°è¡Œæ¥­çš„æ•´é«”å½±éŸ¿

ğŸ“‹ **è¼¸å‡ºè¦æ±‚**ï¼š
è«‹åš´æ ¼æŒ‰ç…§ä»¥ä¸‹XMLæ ¼å¼è¼¸å‡ºåˆ†æçµæœï¼š

{xml_schema}

ğŸ“„ **å¾…åˆ†ææ–‡ç« **ï¼š
{content}

è«‹ç¢ºä¿å•†æ¥­è¡“èªæº–ç¢ºï¼Œæ•¸æ“šåˆ†æå®¢è§€ï¼Œå¼•è¨€æ­¸å±¬æ­£ç¢ºã€‚
"""
        
        return templates
    
    def _init_quote_templates(self) -> Dict[str, str]:
        """åˆå§‹åŒ–äººç‰©å¼•è¨€æå–æ¨¡æ¿"""
        return {
            "precise_matching": """
è«‹ç²¾ç¢ºåŒ¹é…ä»¥ä¸‹äººç‰©èˆ‡å…¶åœ¨æ–‡ç« ä¸­çš„å¯¦éš›å¼•è¨€ã€‚é€™æ˜¯ä¿®å¾©å¼•è¨€æ­¸å±¬éŒ¯èª¤çš„é—œéµä»»å‹™ã€‚

ğŸ¯ **ä»»å‹™é‡é»**ï¼š
- ç¢ºä¿æ¯å€‹å¼•è¨€æ­£ç¢ºæ­¸å±¬æ–¼èªªè©±è€…
- åªæå–ç›´æ¥å¼•è¨€ï¼ˆå¼•è™Ÿå…§å®¹æˆ–æ˜ç¢ºèªªè©±æ¨™è¨˜å¾Œçš„å…§å®¹ï¼‰
- é¿å…å°‡åŒä¸€å¥è©±åˆ†é…çµ¦å¤šå€‹äººç‰©

âš ï¸ **åš´æ ¼è¦æ±‚**ï¼š
1. ä»”ç´°åˆ†ææ¯å€‹"è¡¨ç¤º"ã€"æŒ‡å‡º"ã€"ä»–èªª"ã€"å¥¹èªª"å‰å¾Œçš„äººç‰©åç¨±
2. å¦‚æœæŸäººç‰©åœ¨æ–‡ç« ä¸­æ²’æœ‰ç›´æ¥å¼•è¨€ï¼Œè¿”å›ç©ºæ•¸çµ„
3. ä¸è¦æ¨æ¸¬æˆ–è£œå……æ²’æœ‰æ˜ç¢ºæ¨™ç¤ºçš„å…§å®¹
4. ä¿æŒå¼•è¨€çš„åŸå§‹å®Œæ•´æ€§

ğŸ” **äººç‰©åˆ—è¡¨**ï¼š
{person_names}

ğŸ“‹ **è¼¸å‡ºæ ¼å¼**ï¼š
è«‹ä»¥JSONæ ¼å¼è¿”å›ï¼š
```json
{{
    "quote_extraction": {{
        "person_name_1": ["å¯¦éš›å¼•è¨€1", "å¯¦éš›å¼•è¨€2"],
        "person_name_2": ["å¯¦éš›å¼•è¨€3"],
        "person_name_3": []
    }},
    "extraction_confidence": {{
        "person_name_1": 0.95,
        "person_name_2": 0.90,
        "person_name_3": 0.0
    }},
    "problematic_matches": [
        {{"person": "name", "issue": "æè¿°å•é¡Œ", "original_text": "åŸæ–‡æ®µè½"}}
    ]
}}
```

ğŸ“„ **æ–‡ç« å…§å®¹**ï¼š
{content}

âš¡ **ä¿®å¾©é‡é»**ï¼šé€™æ˜¯è§£æ±ºã€Œæ‰€æœ‰äººç‰©è¢«åˆ†é…ç›¸åŒå¼•è¨€ã€bugçš„é—œéµæ­¥é©Ÿï¼Œè«‹æ ¼å¤–ä»”ç´°ã€‚
""",
            
            "context_aware": """
åŸºæ–¼æ–‡ç« ä¸Šä¸‹æ–‡ï¼Œæ™ºèƒ½æå–äººç‰©è§€é»å’Œç«‹å ´ï¼š

ğŸ” **æå–ç›®æ¨™**ï¼š
- ç›´æ¥å¼•è¨€ï¼ˆå¼•è™Ÿæ¨™è¨˜ï¼‰
- é–“æ¥è§€é»ï¼ˆè½‰è¿°å…§å®¹ï¼‰
- ç«‹å ´æ…‹åº¦ï¼ˆæ”¯æŒ/åå°/ä¸­æ€§ï¼‰
- å°ˆæ¥­åˆ¤æ–·ï¼ˆåŸºæ–¼è§’è‰²èº«ä»½ï¼‰

ğŸ“‹ **ä¸Šä¸‹æ–‡åˆ†æ**ï¼š
è«‹è€ƒæ…®äººç‰©çš„ï¼š
- è·æ¥­èƒŒæ™¯å’Œå°ˆæ¥­é ˜åŸŸ
- åœ¨äº‹ä»¶ä¸­çš„è§’è‰²å®šä½
- èˆ‡å…¶ä»–äººç‰©çš„é—œä¿‚
- è§€é»çš„ä¸€è‡´æ€§å’Œé‚è¼¯æ€§

ğŸ“„ **æ–‡ç« å…§å®¹**ï¼š
{content}

è«‹æä¾›çµæ§‹åŒ–çš„äººç‰©è§€é»åˆ†æã€‚
"""
        }
    
    def _init_keyword_templates(self) -> Dict[str, str]:
        """åˆå§‹åŒ–é—œéµè©ç”Ÿæˆæ¨¡æ¿"""
        return {
            "dynamic_semantic": """
åŸºæ–¼æ–‡ç« å…§å®¹å’Œä¸»é¡Œï¼Œå‹•æ…‹ç”Ÿæˆæœ€ç›¸é—œçš„èªç¾©é—œéµè©ï¼š

ğŸ¯ **ç”Ÿæˆç›®æ¨™**ï¼š
- æ ¸å¿ƒæ¦‚å¿µè©å½™ï¼ˆ5-8å€‹ï¼‰
- å‹•ä½œæè¿°è©å½™ï¼ˆ3-5å€‹ï¼‰
- æƒ…æ„Ÿè¡¨é”è©å½™ï¼ˆ3-5å€‹ï¼‰
- æŠ€è¡“å°ˆæ¥­è©å½™ï¼ˆ5-10å€‹ï¼Œå¦‚é©ç”¨ï¼‰

ğŸ“‹ **è³ªé‡æ¨™æº–**ï¼š
1. é—œéµè©å¿…é ˆåœ¨æ–‡ç« ä¸­çœŸå¯¦å‡ºç¾æˆ–ç›´æ¥ç›¸é—œ
2. é¿å…éæ–¼é€šç”¨çš„è©å½™ï¼ˆå¦‚"é‡è¦"ã€"å¾ˆå¥½"ï¼‰
3. å„ªå…ˆé¸æ“‡èƒ½é«”ç¾æ–‡ç« æ ¸å¿ƒç‰¹è‰²çš„è©å½™
4. è€ƒæ…®å¾ŒçºŒå‰ªè¼¯åŒ¹é…çš„å¯¦ç”¨æ€§

âš ï¸ **ç¦æ­¢ç¡¬ç·¨ç¢¼**ï¼š
- ä¸ä½¿ç”¨é è¨­å­—å…¸
- ä¸ä¾è³´å›ºå®šè¦å‰‡
- å®Œå…¨åŸºæ–¼å…§å®¹å‹•æ…‹ç”Ÿæˆ

ğŸ“‹ **è¼¸å‡ºæ ¼å¼**ï¼š
```json
{{
    "content_keywords": ["é—œéµè©1", "é—œéµè©2", ...],
    "action_keywords": ["å‹•ä½œè©1", "å‹•ä½œè©2", ...],
    "emotion_keywords": ["æƒ…æ„Ÿè©1", "æƒ…æ„Ÿè©2", ...],
    "technical_keywords": ["æŠ€è¡“è©1", "æŠ€è¡“è©2", ...],
    "keyword_confidence": {{
        "content": 0.9,
        "action": 0.85,
        "emotion": 0.8,
        "technical": 0.95
    }}
}}
```

ğŸ“„ **æ–‡ç« å…§å®¹**ï¼š
{content}

è«‹ç¢ºä¿ç”Ÿæˆçš„é—œéµè©å…·æœ‰é«˜åº¦ç›¸é—œæ€§å’Œå¯¦ç”¨åƒ¹å€¼ã€‚
""",
            
            "context_enhanced": """
çµåˆæ–‡ç« ä¸»é¡Œå’Œä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œç”Ÿæˆå¢å¼·å‹èªç¾©æ¨™ç±¤ï¼š

ğŸ” **å¢å¼·è¦ç´ **ï¼š
- æ–‡ç« æ¨™é¡Œå’Œå‰¯æ¨™é¡Œ
- æ®µè½å±¤æ¬¡çµæ§‹
- äººç‰©è§’è‰²é—œä¿‚
- äº‹ä»¶ç™¼å±•è„ˆçµ¡

ğŸ“‹ **ä¸Šä¸‹æ–‡ä¿¡æ¯**ï¼š
- ä¸»é¡Œé¡å‹ï¼š{article_type}
- æ ¸å¿ƒäººç‰©ï¼š{key_persons}
- ä¸»è¦äº‹ä»¶ï¼š{main_events}

ğŸ“„ **æ–‡ç« å…§å®¹**ï¼š
{content}

è«‹ç”Ÿæˆä¸Šä¸‹æ–‡å¢å¼·çš„èªç¾©æ¨™ç±¤é›†åˆã€‚
"""
        }
    
    def _init_topic_contexts(self) -> Dict[ArticleType, Dict]:
        """åˆå§‹åŒ–ä¸»é¡Œç‰¹å®šä¸Šä¸‹æ–‡"""
        return {
            ArticleType.TECHNOLOGY: {
                "focus_areas": ["æŠ€è¡“å‰µæ–°", "ç”¢å“åŠŸèƒ½", "å¸‚å ´æ‡‰ç”¨", "å°ˆå®¶è©•åƒ¹"],
                "key_entities": ["æŠ€è¡“å…¬å¸", "ç”¢å“åç¨±", "æŠ€è¡“è¦æ ¼", "æ‡‰ç”¨å ´æ™¯"],
                "visual_requirements": ["ç”¢å“æ¼”ç¤º", "æŠ€è¡“åœ–è¡¨", "å¯¦éš›æ‡‰ç”¨", "ç”¨æˆ¶åæ‡‰"],
                "pacing_style": "ç§‘æŠ€æ„Ÿå¿«ç¯€å¥"
            },
            
            ArticleType.BUSINESS: {
                "focus_areas": ["è²¡å‹™æ•¸æ“š", "å¸‚å ´ç­–ç•¥", "ç«¶çˆ­åˆ†æ", "é«˜ç®¡è§€é»"],
                "key_entities": ["ä¸Šå¸‚å…¬å¸", "è²¡å‹™æŒ‡æ¨™", "å¸‚å ´æ•¸æ“š", "å•†æ¥­æ¨¡å¼"],
                "visual_requirements": ["ä¼æ¥­æ¨™èªŒ", "æ•¸æ“šåœ–è¡¨", "é«˜ç®¡è¨ªè«‡", "è¾¦å…¬å ´æ™¯"],
                "pacing_style": "ç©©é‡å°ˆæ¥­ç¯€å¥"
            },
            
            ArticleType.GENERAL: {
                "focus_areas": ["äº‹ä»¶ç™¼å±•", "äººç‰©è§€é»", "ç¤¾æœƒå½±éŸ¿", "æœªä¾†å±•æœ›"],
                "key_entities": ["é—œéµäººç‰©", "é‡è¦æ©Ÿæ§‹", "äº‹ä»¶åœ°é»", "æ™‚é–“ç¯€é»"],
                "visual_requirements": ["ç¾å ´ç•«é¢", "äººç‰©è¨ªè«‡", "ç›¸é—œå ´æ™¯", "èƒŒæ™¯è³‡æ–™"],
                "pacing_style": "å¹³è¡¡æ•˜äº‹ç¯€å¥"
            }
        }
    
    def get_semantic_analysis_prompt(self, 
                                   content: str, 
                                   article_type: ArticleType = ArticleType.GENERAL,
                                   additional_context: Dict = None) -> str:
        """ç²å–èªç¾©åˆ†ææç¤ºè©"""
        
        template = self.semantic_analysis_templates.get(
            article_type, 
            self.semantic_analysis_templates[ArticleType.GENERAL]
        )
        
        xml_schema = self.base_xml_schema
        
        # æ ¹æ“šæ–‡ç« é¡å‹èª¿æ•´XMLçµæ§‹
        if article_type == ArticleType.TECHNOLOGY:
            xml_schema = xml_schema.replace(
                "<technical_concepts>",
                "<technical_concepts><!-- ç§‘æŠ€æ–°èé‡é»åˆ†æ -->"
            )
        
        # ä¿®å¾©XML schemaä¸­çš„ä½”ä½ç¬¦
        from datetime import datetime
        xml_schema = xml_schema.format(
            article_type=article_type.value,
            main_topic="å¾…åˆ†æ",
            timestamp=datetime.now().isoformat()
        )
        
        return template.format(
            content=content,
            xml_schema=xml_schema
        )
    
    def get_quote_extraction_prompt(self, 
                                  content: str, 
                                  person_names: List[str],
                                  extraction_type: str = "precise_matching") -> str:
        """ç²å–äººç‰©å¼•è¨€æå–æç¤ºè©"""
        
        template = self.quote_extraction_templates.get(
            extraction_type,
            self.quote_extraction_templates["precise_matching"]
        )
        
        names_str = ", ".join(person_names) if person_names else "ç„¡æ˜ç¢ºäººç‰©åˆ—è¡¨"
        
        return template.format(
            content=content,
            person_names=names_str
        )
    
    def get_keyword_generation_prompt(self, 
                                    content: str,
                                    article_type: ArticleType = ArticleType.GENERAL,
                                    key_persons: List[str] = None,
                                    main_events: List[str] = None) -> str:
        """ç²å–é—œéµè©ç”Ÿæˆæç¤ºè©"""
        
        # é¸æ“‡åŸºç¤æ¨¡æ¿
        if key_persons or main_events:
            template = self.keyword_generation_templates["context_enhanced"]
            return template.format(
                content=content,
                article_type=article_type.value,
                key_persons=", ".join(key_persons) if key_persons else "æœªæŒ‡å®š",
                main_events=", ".join(main_events) if main_events else "æœªæŒ‡å®š"
            )
        else:
            template = self.keyword_generation_templates["dynamic_semantic"]
            return template.format(content=content)
    
    def get_topic_context(self, article_type: ArticleType) -> Dict:
        """ç²å–ä¸»é¡Œç‰¹å®šä¸Šä¸‹æ–‡"""
        return self.topic_contexts.get(
            article_type,
            self.topic_contexts[ArticleType.GENERAL]
        )
    
    def detect_article_type(self, content: str, title: str = "") -> ArticleType:
        """è‡ªå‹•æª¢æ¸¬æ–‡ç« é¡å‹"""
        
        # çµåˆæ¨™é¡Œå’Œå…§å®¹é€²è¡Œæª¢æ¸¬
        full_text = f"{title} {content}".lower()
        
        # å®šç¾©å„é¡å‹çš„é—œéµè©æŒ‡æ¨™
        type_indicators = {
            ArticleType.TECHNOLOGY: [
                "ç§‘æŠ€", "æŠ€è¡“", "AI", "äººå·¥æ™ºæ…§", "ç„¡äººæ©Ÿ", "æ©Ÿå™¨äºº", "è»Ÿé«”", "ç¡¬é«”",
                "å‰µæ–°", "æ•¸ä½", "æ™ºèƒ½", "ç³»çµ±", "å¹³å°", "æ‡‰ç”¨", "é–‹ç™¼", "ç¨‹å¼"
            ],
            ArticleType.BUSINESS: [
                "è‚¡åƒ¹", "ç‡Ÿæ”¶", "è²¡å ±", "æŠ•è³‡", "å¸‚å ´", "ä¼æ¥­", "å…¬å¸", "å•†æ¥­",
                "ç¶“æ¿Ÿ", "ç”¢æ¥­", "æ¥­ç¸¾", "ç²åˆ©", "è³‡é‡‘", "ä½µè³¼", "ä¸Šå¸‚", "è‘£äº‹"
            ],
            ArticleType.POLITICS: [
                "æ”¿åºœ", "ç¸½çµ±", "ç«‹æ³•é™¢", "æ”¿ç­–", "é¸èˆ‰", "æ”¿æ²»", "æ³•æ¡ˆ", "éƒ¨é•·",
                "å¸‚é•·", "è­°æœƒ", "è¡Œæ”¿", "æ³•å¾‹", "æ¢ä¾‹", "å…¬å…±", "æ°‘çœ¾", "ç¤¾æœƒ"
            ],
            ArticleType.SPORTS: [
                "æ¯”è³½", "é‹å‹•", "é¸æ‰‹", "å† è»", "çƒéšŠ", "æ•™ç·´", "è³½äº‹", "é«”è‚²",
                "ç«¶æŠ€", "è¨“ç·´", "æˆç¸¾", "ç´€éŒ„", "è¯ç›Ÿ", "çƒå“¡", "å‹åˆ©", "defeats"
            ],
            ArticleType.EDUCATION: [
                "å­¸æ ¡", "æ•™è‚²", "å­¸ç”Ÿ", "è€å¸«", "èª²ç¨‹", "å­¸ç¿’", "æ ¡é•·", "å¤§å­¸",
                "ç ”ç©¶", "å­¸è¡“", "çŸ¥è­˜", "åŸ¹è¨“", "æ•™å­¸", "è€ƒè©¦", "ç•¢æ¥­", "æ‹›ç”Ÿ"
            ]
        }
        
        # è¨ˆç®—å„é¡å‹çš„åŒ¹é…åˆ†æ•¸
        type_scores = {}
        for article_type, keywords in type_indicators.items():
            score = sum(1 for keyword in keywords if keyword in full_text)
            type_scores[article_type] = score
        
        # æ‰¾å‡ºæœ€é«˜åˆ†çš„é¡å‹
        if type_scores:
            best_type = max(type_scores, key=type_scores.get)
            if type_scores[best_type] > 0:
                logger.info(f"æª¢æ¸¬åˆ°æ–‡ç« é¡å‹: {best_type.value}")
                return best_type
        
        logger.info("ç„¡æ³•ç¢ºå®šæ–‡ç« é¡å‹ï¼Œä½¿ç”¨ä¸€èˆ¬é¡å‹")
        return ArticleType.GENERAL

# ä¾¿åˆ©å‡½æ•¸
def create_prompt_manager() -> PromptTemplateManager:
    """å‰µå»ºæç¤ºè©æ¨¡æ¿ç®¡ç†å™¨å¯¦ä¾‹"""
    return PromptTemplateManager()

# æ¸¬è©¦å‡½æ•¸
def test_prompt_templates():
    """æ¸¬è©¦æç¤ºè©æ¨¡æ¿åŠŸèƒ½"""
    manager = PromptTemplateManager()
    
    test_content = """
    ç™¼å±•ç§‘æŠ€æ‡‰ç”¨èƒ½åŠ›ã€€å¸‚å…¬æ‰€æ”œæ‰‹èŠ±è“®ç¤¾å¤§é»ç‡ƒç„¡äººæ©Ÿå­¸ç¿’ç†±æ½®
    
    éš¨è‘—ç§‘æŠ€é€²æ­¥èˆ‡æ‡‰ç”¨å ´åŸŸæ“´å±•ï¼Œç„¡äººæ©Ÿå·²å¾è»äº‹ç§‘æŠ€èµ°å…¥æ°‘é–“ç”Ÿæ´»ã€‚ç‚ºæ¨å»£ç„¡äººæ©ŸçŸ¥è­˜èˆ‡æ‡‰ç”¨å¯¦å‹™ï¼ŒèŠ±è“®å¸‚å…¬æ‰€ã€èŠ±è“®ç¸£ç¤¾å€å¤§å­¸èˆ‡å°ç£åœ‹éš›ç„¡äººæ©Ÿç«¶æŠ€ç™¼å±•å”æœƒèŠ±è“®åˆ†æœƒæ–¼28æ—¥ä¸Šåˆï¼Œåœ¨åŒ–ä»åœ‹ä¸­è¯åˆèˆ‰è¾¦ã€Œç„¡äººæ©Ÿæ™‚ä»£ä¾†äº†ã€æŠ€è¡“è¬›åº§ï¼Œç«¶æŠ€é™æ§æ¨¡å‹ç›´å‡æ©Ÿä¸–ç•Œå† è»æ—ä½ç¿°ä¹Ÿç¾å ´å±•æ¼”ç©¿è¶Šæ©ŸåŠç„¡äººç›´å‡æ©Ÿé£›è¡Œæ§åˆ¶æŠ€å·§ã€‚
    
    æ—ä½ç¿°è¡¨ç¤ºï¼Œ2016å¹´åƒåŠ äºæ‹“ç›ƒæ¦®ç²ç›´å‡æ©Ÿçµ„ç¬¬ä¸€åï¼Œç²å» å•†é’çç°½ç´„æˆç‚ºè©¦é£›å“¡ã€‚ä»–æœŸæœ›æ›´å¤šå¹´è¼•äººæŠ•å…¥ï¼Œç›¸ä¿¡å°ç£é£›æ‰‹å¯¦åŠ›å …å¼·ã€‚
    """
    
    # æ¸¬è©¦æ–‡ç« é¡å‹æª¢æ¸¬
    article_type = manager.detect_article_type(test_content)
    print(f"æª¢æ¸¬åˆ°çš„æ–‡ç« é¡å‹: {article_type.value}")
    
    # æ¸¬è©¦èªç¾©åˆ†ææç¤ºè©
    semantic_prompt = manager.get_semantic_analysis_prompt(test_content, article_type)
    print(f"\nèªç¾©åˆ†ææç¤ºè©é•·åº¦: {len(semantic_prompt)} å­—ç¬¦")
    
    # æ¸¬è©¦å¼•è¨€æå–æç¤ºè©
    quote_prompt = manager.get_quote_extraction_prompt(
        test_content, 
        ["æ—ä½ç¿°"]
    )
    print(f"å¼•è¨€æå–æç¤ºè©é•·åº¦: {len(quote_prompt)} å­—ç¬¦")
    
    # æ¸¬è©¦é—œéµè©ç”Ÿæˆæç¤ºè©
    keyword_prompt = manager.get_keyword_generation_prompt(test_content, article_type)
    print(f"é—œéµè©ç”Ÿæˆæç¤ºè©é•·åº¦: {len(keyword_prompt)} å­—ç¬¦")
    
    print("\nâœ… æç¤ºè©æ¨¡æ¿æ¸¬è©¦å®Œæˆ")

if __name__ == "__main__":
    test_prompt_templates()